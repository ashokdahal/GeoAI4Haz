
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Best practices in the training of Machine Learning models &#8212; Machine Learning for Natural Hazards</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '07_bestpractice';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="More on gradient-based optimization" href="08_gradopt1.html" />
    <link rel="prev" title="More on Neural Networks" href="06_nn.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="README.html">
  
  
  
  
  
  
    <p class="title logo__title">Machine Learning for Natural Hazards</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="README.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Background and Refresher</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_intro.html">Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_linalg.html">Linear Algebra refresher</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_gradopt.html">Gradient-based optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_linreg.html">Linear and Logistic Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Neural Networks</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="05_nn.html">Basics of Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_nn.html">More on Neural Networks</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Best practices in the training of Machine Learning models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="08_gradopt1.html">More on gradient-based optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_cnn.html">Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_cnnarch.html">CNNs Popular Architectures</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ashokdahal/GeoAI4Haz" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ashokdahal/GeoAI4Haz/issues/new?title=Issue%20on%20page%20%2F07_bestpractice.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/07_bestpractice.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Best practices in the training of Machine Learning models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#capacity">Capacity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-hyperparameters">Other hyperparameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization">Regularization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dropout">Dropout</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augumentation">Data augumentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">Transfer learning</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="best-practices-in-the-training-of-machine-learning-models">
<h1>Best practices in the training of Machine Learning models<a class="headerlink" href="#best-practices-in-the-training-of-machine-learning-models" title="Link to this heading">#</a></h1>
<p>This lecture is devoted to the training of Machine Learning models in general, with Neural Networks
representing a subclass of the entire set of models commonly used to learn mappings between some
features and targets. As we will see in the following, a number of <code class="docutils literal notranslate"><span class="pre">best</span> <span class="pre">practices</span></code> are in fact
independent on the model used.</p>
<p>Let’s begin by re-stating here the overall aim of a ML model: a model is useful if it can perform
well on new, previously unseen data. This property of a model is also generally referred to as
<em>generalization</em>.</p>
<p>In order to be able to assess the generalization capabilities of a model, the dataset available for
training must be divided into 3 distinct sets:</p>
<ul class="simple">
<li><p>Training dataset: <span class="math notranslate nohighlight">\(\{ \mathbf{X}_{train}, \mathbf{Y}_{train} \}\)</span>, used to train the model
(e.g., learn the free-parameters <span class="math notranslate nohighlight">\(\boldsymbol \theta\)</span> of a NN);</p></li>
<li><p>Validation dataset: <span class="math notranslate nohighlight">\(\{ \mathbf{X}_{valid}, \mathbf{Y}_{valid} \}\)</span>, used to select the hyperparameters of
the model;</p></li>
<li><p>Testing dataset:<span class="math notranslate nohighlight">\(\{ \mathbf{X}_{test}, \mathbf{Y}_{test} \}\)</span>, used only once a model is finalized
(trained and optimized) to produce an <em>unbiased</em> estimate of model performance.</p></li>
</ul>
<p>Note that a number of assumptions are usually made on the training samples, namely each sample is
independent from the others, samples must come from the same distributions. The first assumption
is however seldom satisfied as a different training samples are related to each other to some degree (this is for example
the case when samples are taken from well logs at consecutive depth levels or from 2D slices of 3D seismic
cubes). On the other hand, the second assumption must be satisfied for a successful training. For example, if well logs
from the North Sea are used in the training data and well logs from Onshore US are used in the testing data,
any estimate of model performance will be biased as the two sets are likely to belong to different distributions.</p>
<p>Historically, the overall dataset is split into training/validation/testing data with the following proportions:
60%/20%/20%. This is the case for small datasets in the order of hundreds or thousands samples to be able to
retain a large enough set to produce reliable statistics. In recent years, when training neural networks with
large datasets (in the order of millions or more samples), the split is more commonly chosen as
98%/1%/1%. As the size of datasets in geoscientific applications is usually in between what we referred to as small
and large datasets, choosing validation and training sets that are 5%/10% of the overall dataset is
usually a good choice.</p>
<p>A measure must be then chosen to evaluate the performance of such a model in terms of the
estimation error after training. This can be for example the MSE for regression tasks, or cross-entropy for classification tasks.
Two quantities are generally computed:</p>
<ul class="simple">
<li><p><strong>Training error</strong> (or performance): overall error (or performance) computed over the training dataset;</p></li>
<li><p><strong>Test/Generalization error</strong> (or performance): overall error (or performance) computed over the testing dataset.</p></li>
</ul>
<p>The goodness of machine learning model is usually evaluated based on the following two criteria:</p>
<ul class="simple">
<li><p><strong>Bias</strong>: ability to produce a small training error. When the error is small, we say that we have a model with low bias.
Vice versa, when the error is large, the model have high bias. In this case, the model is said to be <em>underfitting</em> the data;</p></li>
<li><p><strong>Variance</strong>: ability to produce comparable training and testing error. In other words, if we define
<em>gap</em> to be the difference between the testing and training errors, this is also the ability to produce a
small gap. When the gap is large, the model is said to be <em>overfitting</em> the data.</p></li>
</ul>
<p>Finally, no matter how large the training dataset and the model capacity are, the bias and variance are likely to be always
present. So, an important question to ask ourselves when working on a ML project is ‘how far can the performance of the model be pushed further?’.
Or, in other words, can we expect further hyperparameter tuning to be successfully improving the model significantly or the model has
reached a plateau in terms of learning capabilities.</p>
<p>To answer the above question, we need to first consider two distinct scenarios:</p>
<ul class="simple">
<li><p>the network is designed to solve a task that a human can also solve (e.g., interpreting faults and horizons in seismic volumes)</p></li>
<li><p>the network is performing a task that a human is not able to perform (e.g., denoising a seismic volume).</p></li>
</ul>
<p>In the former case, it is possible to define the so-called <em>human-level performance</em> (i.e., error that a human is
likely to make on the task at hand). Experience in the field of deep learning has shown that the performance of a model (e.g., accuracy in
classification tasks) depends on the development time of a ML model in such a way that a well-designed model will
very quickly reach human-level performance, whilst a much more significant effort is required to obtain further improvements
and approach the theoretical limit of the model. Such a limit, called the Bayesian optimal error, is the error of
an oracle making predictions. In practical applications this may however be unknown, unless the training data has been generated in such
a way that true exact labels are available.</p>
<p><img alt="MLPERFORMANCE" src="_images/mlperformance.png" /></p>
<p>In a range of geoscientific applications, human-level performance may be replaced by the state-of-the-art algorithm that is
commonly used to perform a certain task. For example, going back to the denoising example, this may be represented by FX prediction
filters or SVD-based denoising. Such an algorithm can represent the human performance in the above figure and represent a
baseline that we would like our model to outperform. At the same time, as no human labels are available, the use of synthetic data with true labels usually represent the only viable solution to creating a training dataset in this scenario. This time, the theoretical limit represented by the true labels can again guide us into how much effort we should put to improve the hyperparameters of the model.</p>
<p>To conclude, let’s consider two examples of ML classifiers. In the first, after some development time,
our ML model performs as follows:</p>
<ul class="simple">
<li><p>human-level percentage error: 2%</p></li>
<li><p>training percentage error: 10%</p></li>
<li><p>validation percentage error: 12%</p></li>
</ul>
<p>In this scenario, we clearly observe a large bias and a much smaller variance. This bias, usually referred to as
<em>avoidable bias</em> is what we should focus next in our ML development time.</p>
<p>On the other hand, if we observe the following:</p>
<ul class="simple">
<li><p>human-level percentage error: 2%</p></li>
<li><p>training percentage error: 4%</p></li>
<li><p>validation percentage error: 20%</p></li>
</ul>
<p>This model shows a small bias and a large variance. Our ML development time should be therefore devoted to reduce the generalization gap. On the other hand, since the difference between human-level and training error is minimal, we refer to this error as <em>unavoidable bias</em> that may be very difficult to further reduce.</p>
<p>In the following we discuss a number of strategies that are commonly used in the process of improving the model
and reducing both bias and variance.</p>
<section id="capacity">
<h2>Capacity<a class="headerlink" href="#capacity" title="Link to this heading">#</a></h2>
<p>A key aspect in the process of designing a ML model that can both fit the available data and generalize to
new, unseen data is represented by the size, or more formally speaking the <em>capacity</em> of the model. Simply put, this is the
number of free parameters <span class="math notranslate nohighlight">\(\theta\)</span> that the model is allowed to optimize in the training process.</p>
<p>Let’s begin with an example of linear regression, where the model is defined as follows:</p>
<div class="math notranslate nohighlight">
\[
y_i = f_{\boldsymbol \theta}(x_i) = \sum_{j=0}^{N_f} x_i^j \theta_j \qquad \forall i=1,2,...,N_s
\]</div>
<p>where <span class="math notranslate nohighlight">\(N_f+1\)</span> is the capacity of the model. The simplest model that we can fit to the available data
is straight line parametrized by <span class="math notranslate nohighlight">\(\boldsymbol \theta = {\theta_1, \theta_2}\)</span>. More complex model fit a
polynomial function of order <span class="math notranslate nohighlight">\(N_f+1\)</span>. As shown in the figure below, a too simple model does lead to underfitting,
whilst a too complex model leads to overfitting. The key is therefore to make a model that is as simple as possible
but not too simple, something usually referred to as the Occam’s razor principle in inverse problem theory.</p>
<p><img alt="CAPACITY" src="_images/capacity.png" /></p>
<p>Similar principles apply to the design of a neural network. In this case however, the risk of overfitting is
much higher due to ability of NNs to learn very complex nonlinear functions. The size of the training dataset
plays a key role in choosing the capacity of the network: large networks with thousands (or millions) of free-parameters
require large training dataset to avoid the arising of overfitting. Moreover, as shown in the figure below,
training and testing errors are usually similar for small networks in the underfitting regimes and tend to reduce
together as the network size increases. However, when the capacity of the network grows into the overfitting
regime, the training error keeps decreasing whilst the testing error starts to increase. Note that the
training error should always reduce when increasing the size of the network, therefore it cannot be used
to choose the ideal network capacity. This shows the importance of holding some of the available data for validation
purposes. i.e., hyperparameter optimization.</p>
<p><img alt="GENERALIZATION" src="_images/generalization.png" /></p>
</section>
<section id="other-hyperparameters">
<h2>Other hyperparameters<a class="headerlink" href="#other-hyperparameters" title="Link to this heading">#</a></h2>
<p>Whilst the size of the network largely drives the ability of a model to learn as well as its tendency to overfit, unfortunately
(or fortunately, depending of the point of view of the reader), when designing a ML model you will likely need to make decisions on a number of additional hyperparameters. Here we report some of the most important ones:</p>
<ul class="simple">
<li><p>activation function;</p></li>
<li><p>optimizer,</p></li>
<li><p>learning rate</p></li>
<li><p>additional optimizer hyperparameters,</p></li>
<li><p>batch size…</p></li>
</ul>
<p>As already mentioned, we need to devote a portion of the overall dataset that we will not be using to evaluate the final performance of the model for the task of <em>hyperparameter tuning</em>. This is indeed the role of the validation dataset (note that using this dataset at testing stage will result in underestimating the generalization error of the model because the model is partially optimized on this dataset).</p>
<p>Finally, whilst not very commonly used in the context of deep learning because of the extremely high cost of training neural networks, a more powerful approach in optimizing hyper-parameter is the so-called <em>cross-validations</em> strategy. Similar to validation, a portion of the dataset is hold out from the training process and used for hyperparameter tuning. However, the portion selected for this task is not fixed, rather the entire training dataset is split into K groups, where each group is used once as the validation set and the remaining number of times as part of the training dataset.</p>
<p>This approach, usually referred to a <em>K-fold cross-validation</em>. It is a great help when the training dataset is of limited size as it helps averaging out fluctuations on the validation error over multiple realizations. The obvious downside of this strategy is of course that the training process must be repeated N times.</p>
<p>Note that other strategies can be used to split the dataset into training and validation. For example, in the context of classification, a class-aware division is usually recommended where inter-class proportions are the same between the validation and training datasets.</p>
</section>
<section id="regularization">
<h2>Regularization<a class="headerlink" href="#regularization" title="Link to this heading">#</a></h2>
<p>Whilst both under- and overfitting commonly affect the development of a successful ML model, reducing variance without affecting
bias is notoriously difficult. A strategy that is usually successful in achieving such a task is called Regularization.
Regularization acts directly on the loss function by adding prior knowledge to the training process. By informing the network
about something that we know (or wish the model to know), the network is less prone to just learn from the training data and improve its generalization capabilities.</p>
<p>In the context of inverse problem theory, where our aim is to fit some observations <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> given knowledge of
the underlying physical process (<span class="math notranslate nohighlight">\(g\)</span>),</p>
<div class="math notranslate nohighlight">
\[
J = ||\mathbf{y} - g(\mathbf{x})||_2^2 + \lambda R(\mathbf{x})
\]</div>
<p>regularization can come in different flavours, more specifically:</p>
<ul class="simple">
<li><p><em>Tikhonov (or L2) regularization</em>: <span class="math notranslate nohighlight">\(||\mathbf{x}||_2^2\)</span>. Ensures that a model with small norm is favoured over other models
equally fitting the data. This promotes simplicity (or parsimony) in the solution</p></li>
<li><p><em>Generalized Tikhonov regularization</em>: e.g., <span class="math notranslate nohighlight">\(||\nabla \mathbf{x}||_2^2\)</span>, where <span class="math notranslate nohighlight">\(\nabla\)</span> is the laplacian operator. Ensures that a smooth model is favoured over a rough one by
second derivative of the model (i.e., curvature).</p></li>
<li><p><em>L1 regularization or sparsity</em>: <span class="math notranslate nohighlight">\(||\mathbf{x}||_p \; p \le 1\)</span>. Promotes solutions that are sparse (i.e., few non-zero elements)</p></li>
</ul>
<p>A similar approach can be adopted in the context of machine learning by augmenting the data-fitting loss function with a regularization term:</p>
<div class="math notranslate nohighlight">
\[
J_\theta = \frac{1}{N_s} \sum_{i=1}^{N_s} ||y^{(i)} - f_\theta(\mathbf{x}^{(i)})||_2^2 + \lambda R(\theta)
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><em>L2 regularization or weight decay</em>: <span class="math notranslate nohighlight">\(||\boldsymbol \theta||_2^2= \boldsymbol \theta^T \boldsymbol \theta\)</span>. Ensures small Euclidean norm for the free-parameters;</p></li>
<li><p><em>L1 regularization</em>: <span class="math notranslate nohighlight">\(||\boldsymbol \theta||_1\)</span>. Ensures small L1 norm for the free-parameters.
By favouring sparsity in the parameters of the model, this regularization can allow compressing the
trained model by storing only the non-negative parameters and their indices.</p></li>
</ul>
<p>Note that in the statistical community, regression models with one of the two regularizations discussed above
is called Ridge and Lasso regression models, respectively.</p>
<p>Finally, in the special case of deep learning and training by back-propagation the regularization terms and their gradients
can be simply expressed as:</p>
<ul class="simple">
<li><p><em>L2 regularization or weight decay</em>:
$<span class="math notranslate nohighlight">\(
\frac{1}{2 N_s} \sum_{l=1}^{L} ||\mathbf{W}^{[l]}||_2^2 \rightarrow \mathbf{W}^{[l]} = 
\mathbf{W}^{[l]} \big[ 1 - \alpha \frac{\lambda}{N_s} \big] - \alpha \mathbf{dW}^{[l]}
\)</span><span class="math notranslate nohighlight">\(
where the term weight decay comes from the fact that the strength of the current weights is reduced by a factor
of \)</span>\alpha \lambda / N_s$ at every gradient step of the regularized loss function</p></li>
<li><p><em>L1 regularization</em>:
$<span class="math notranslate nohighlight">\(
\sum_{l=1}^{L} ||\mathbf{W}^{[l]}||_2^2 \rightarrow \mathbf{W}^{[l]} = \mathbf{W}^{[l]} - \alpha \mathbf{dW}^{[l]} - \mathbf{W}^{[l]}
\)</span>$</p></li>
</ul>
<p>In both cases <span class="math notranslate nohighlight">\(L\)</span> represents the number of layers in the network. Note that it is common to apply regularization to the weights only (no bias terms).</p>
</section>
<section id="dropout">
<h2>Dropout<a class="headerlink" href="#dropout" title="Link to this heading">#</a></h2>
<p>Dropout represents a special kind of regularization strategy to prevent overfitting, which is specific to Neural Network architectures. Contrarily to other regularization techniques that act directly on the objective function to optimize, dropout modifies the network in such a way that a portion of the neurons are randomly inactivated (i.e., set to zero) during the training process.</p>
<p>A strategy to mitigate overfitting is in fact to reduce the size of the network (i.e., its degrees of freedom) used to match the
training data; however, instead of applying such a drastic approach, dropout allows the overall network size to remain unchanged whilst making the network effectively smaller during training. By doing so, the network learns not to rely
on any neuron (or set of neurons) in particular, which leads to better generalization in validation and testing phases.</p>
<p>Considering a simple 3-layers NN, the nodes at each layer are inactivated with probability <span class="math notranslate nohighlight">\(p_{drop}\)</span>. In the figure below,
<span class="math notranslate nohighlight">\(p_{drop}=0.3\)</span> for the input and first hidden layer, <span class="math notranslate nohighlight">\(p_{drop}=0.5\)</span> for the second hidden layer (and <span class="math notranslate nohighlight">\(p_{drop}=0\)</span> for the
output layer):</p>
<p><img alt="DROPOUT" src="_images/dropout.png" /></p>
<p>Mathematically speaking, if we consider a single node in the figure above, its output can be written as:</p>
<div class="math notranslate nohighlight">
\[
z_2^{[1]} = \frac{W_{21}^{[1]} x_1 + \cancel{W_{22}^{[1]} x_2} + W_{32}^{[1]} x_3 + b_{2}^{[1]}}{1-p_{drop}}
\]</div>
<p>where the second term is removed because <span class="math notranslate nohighlight">\(W_{22}^{[1]}\)</span> is set to zero. Moreover note that a denominator is added to
compensate for the fact that the output is smaller than the one that we would obtain without dropout.</p>
<p>In practice, a more convenient way to implement dropout is to act directly on the input vector at the i-th layer <span class="math notranslate nohighlight">\(\mathbf{a}^{[i-1]}\)</span> instead of deactivating the weights. This approach is called <em>inverted dropout</em> and simply achieved by using a mask <span class="math notranslate nohighlight">\(\mathbf{m}\)</span> where each element is randomly set to 0 or 1 based on <span class="math notranslate nohighlight">\(p_{drop}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{a}^{[i-1]} \rightarrow \tilde{\mathbf{a}}^{[i-1]} = 
\mathbf{a}^{[i-1]} \cdot \mathbf{m} \rightarrow \mathbf{z}^{[i]} = (\mathbf{W}^{[i]} \tilde{\mathbf{a}}^{[i-1]})/(1-p_{drop})
\]</div>
<p>Finally, at testing time, dropout is usually inactivated. Recent research in the area of uncertainty quantification (UQ) for deep learning has however suggested that by using dropout also at testing time, multiple equi-probable realizations of the output can be produced and statistics (e.g., mean, variance, marginal probability…) can be computed. This strategy will be implemented and compared to other strategies for UQ in in this <a class="reference external" href="https://github.com/DIG-Kaust/MLgeoscience/blob/main/labs/notebooks/LearningFunction/LearningFunction.ipynb">lab</a>.</p>
</section>
<section id="data-augumentation">
<h2>Data augumentation<a class="headerlink" href="#data-augumentation" title="Link to this heading">#</a></h2>
<p>One of the key elements to a successful generalization (i.e., low variance) is represented by the
availability of a large training dataset. When this is not the case and it is not feasible to acquire additional
data, an alternative solution is represented by so-called <em>data augmentation</em>. Data augmentation simply refers to
the set of procedures that can be employed to create new artificial data samples by manipulating or combining some of the
original data samples. Whilst this is very data and problem dependant, in the following we will mention a number of strategies
that are commonly used in computer vision when working with natural images. More specifically:</p>
<ul class="simple">
<li><p>cropping,</p></li>
<li><p>flipping,</p></li>
<li><p>rotating,</p></li>
<li><p>shearing,</p></li>
<li><p>averaging,</p></li>
<li><p>color shifting</p></li>
</ul>
<p>are all strategies that can be used or adapted to geoscientific multi-dimensional datasets.
Nevertheless, special attention may be required when implementing some of the above mentioned strategies. Just to give an example, stretching or squeezing time series data such as seismic traces does introduce a shift in the frequency content that may not be desirable. Similarly, applying <code class="docutils literal notranslate"><span class="pre">color</span> <span class="pre">shifting</span></code> to seismic data will lead to a signal whose average is not zero anymore. Alternatively, polarity reversal represents a better alternative that can be seen as a special type of color shifting when dealing with seismic data.</p>
<p>Finally, we observe that although this does not, strictly speaking, fall within the realm of data augmentation, using basic physics principles to create synthetic datasets for training is another commonly employed strategy in geoscience when accessing high-quality labelled datasets is feasible from either a technical or intellectual property point of view. We will see example of a ML workflow that relies on synthetic data when dealing with <a class="reference external" href="https://github.com/DIG-Kaust/MLgeoscience/blob/main/labs/notebooks/EventDetection/EventDetection.ipynb">microseismic event detection</a>.</p>
</section>
<section id="transfer-learning">
<h2>Transfer learning<a class="headerlink" href="#transfer-learning" title="Link to this heading">#</a></h2>
<p>An edge case of data augmentation is represented by transfer learning. Transfer learning is a procedure employed to circumvent the issue or scarce labelled data when <em>similar</em> datasets are available and have been previously used to train a neural network for a similar (or sometimes different task). Under these conditions, one may think to use the pre-trained network and use the available training data to fine-tune such a network for the task at hand. Once again, based on the dataset and problem, the entire pre-trained network may be used as starting point or just a portion of it (generally chosen to be the initial portion of the network where some of the final layers are removed, and referred to as backbone).</p>
<p>To make things a bit more concrete, let’s consider here an example. A NN model has been created to interpret faults in seismic data. Training has been performed using data from an area of the world where both seismic data and fault interpretations are abundant. When a new dataset from the same area becomes available, the pre-trained model can be used as-is or fine-tuned using a much smaller training dataset (i.e., requiring limited manual labelling of faults). A similar strategy could also be used if a new dataset from another area of the world is ready for fault interpretation. In this second case, however, a user needs to
be aware that the model may not generalize well if key features in the data (e.g., frequency content) or interpretation (e.g., presence of reverse faults) are different from those in the original dataset used for training.</p>
<p>A different case where transfer learning can be also used is when the output that we are interested is slightly different from the one the network was trained on but the input is the same (and therefore the low- and medium-level features learned by the network). In this case, one may freeze the first few layers (i.e., make those parameters non-learnable) and fine-tune only the last few layers of the network on the new task. As an example, let’s consider again a network trained for fault interpretation. Imagine now that we are interest to estimate a seismic attribute such as the relative geological time and we have very limited
access to labelled data. In this case the backbone of the network is likely to already contain useful features, and the problem arising from a lack of large training dataset is mitigated by limiting the number of free-parameters to learn to those of the last few layers.</p>
<p><img alt="TRANSFER" src="_images/transferlearning.png" /></p>
<p>To conclude, let’s visually summarize the strategies that we should keep in mind when interested to reduce
bias or variance.</p>
<p><img alt="BIASVARIANCE" src="_images/biasvariance.png" /></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="06_nn.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">More on Neural Networks</p>
      </div>
    </a>
    <a class="right-next"
       href="08_gradopt1.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">More on gradient-based optimization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#capacity">Capacity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-hyperparameters">Other hyperparameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization">Regularization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dropout">Dropout</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augumentation">Data augumentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">Transfer learning</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ashok Dahal, Modified from the Content of Matteo Ravasi, KAUST
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>