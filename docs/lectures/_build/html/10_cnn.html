
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Convolutional Neural Networks &#8212; Machine Learning for Natural Hazards</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '10_cnn';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="CNNs Popular Architectures" href="11_cnnarch.html" />
    <link rel="prev" title="More on gradient-based optimization" href="08_gradopt1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="README.html">
  
  
  
  
  
  
    <p class="title logo__title">Machine Learning for Natural Hazards</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="README.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Background and Refresher</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_intro.html">Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_linalg.html">Linear Algebra refresher</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_gradopt.html">Gradient-based optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_linreg.html">Linear and Logistic Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="05_nn.html">Basics of Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_nn.html">More on Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_bestpractice.html">Best practices in the training of Machine Learning models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="08_gradopt1.html">More on gradient-based optimization</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_cnnarch.html">CNNs Popular Architectures</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ashokdahal/GeoAI4Haz" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ashokdahal/GeoAI4Haz/issues/new?title=Issue%20on%20page%20%2F10_cnn.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/10_cnn.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Convolutional Neural Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolution">Convolution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-convolution">Why Convolution?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#padding-and-strides">Padding and strides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#channels">Channels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-layer">Convolutional layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-network">Convolutional network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pooling">Pooling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#x1-convolutions">1x1 convolutions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-connections">Skip connections</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="convolutional-neural-networks">
<h1>Convolutional Neural Networks<a class="headerlink" href="#convolutional-neural-networks" title="Link to this heading">#</a></h1>
<p>Convolutional Neural Networks are one of the most powerful types of neural network, very popular and successful in image processing (and more broadly computer vision). They are based on a simple mathematical operation that we, geoscientists, know very well and user in a variety of tasks: the <em>convolution</em> operator. This is motivated in most scenarios where local dependencies in the input data are known to be predominant.</p>
<p>Imagine for example a geological model, or a core section. If we decide to apply Deep Learning to such data to either classify
rock types, estimate rock parameters, or even for generative modelling tasks, the first thing that we would like our NN to know is that nearby geological features are likely to be correlated, whilst the further apart we move the more the features become
independent from each other. By looking at the schematic diagrams below, a FCN would not take this prior information into account
as each input value is linearly combined to give rise to the output. On the other hand, a convolutional block which represents
the key component of a CNN will only use values of the input vector in a certain neighbour to obtain the output:</p>
<p><img alt="CNN" src="_images/cnn.png" /></p>
<p>The example mentioned above is just one of many in geoscience where convolution-based networks have been lately shown to be very
successfull. Other examples are:</p>
<ul class="simple">
<li><p><em>Seismic interpretation</em> (faults, horizons, bodies)</p></li>
<li><p><em>Seismic processing</em> (denoising, interpolation, deblurring)</p></li>
<li><p><em>Satellite imaginery</em> (denoising, segmentation)</p></li>
<li><p><em>Microseismicity</em> (detection, source mechanism)</p></li>
<li><p><em>Laboratory studies</em> (CT, SEM, Microscopy for various processing and interpretation tasks)</p></li>
</ul>
<p>In general, any data type that is represented regularly on a 1D, 2D, or ND gridded topology is fit for CNNs.</p>
<section id="convolution">
<h2>Convolution<a class="headerlink" href="#convolution" title="Link to this heading">#</a></h2>
<p>First of all, let’s briefly recall what a convolution is. This represents in fact the core operation performed by a convolutional layer.</p>
<p>A convolution between two signals can be mathematically written as</p>
<div class="math notranslate nohighlight">
\[
y(t) = \int x(\tau) h(t-\tau) d\tau \leftrightarrow y = x * h
\]</div>
<p>where <span class="math notranslate nohighlight">\(x(t)\)</span> and <span class="math notranslate nohighlight">\(y(t)\)</span> are the input and output, respectively, and <span class="math notranslate nohighlight">\(h(t)\)</span> is the filter (also called <em>kernel</em> in the DL jargon).
This equation can be interpreted as follows: take the filter and flip it across the origin, then slide it along the time axis and multiply-and-sum it to the input signal.</p>
<p>In practice, when working with digital data in a computer, all signals are discrete and the continuous formula above can be rewritten as follows:</p>
<div class="math notranslate nohighlight">
\[
y_i = \sum_{j=-\infty}^{\infty} x_j h_{i-j}
\]</div>
<p>where, to be general, we have here extended the integral from <span class="math notranslate nohighlight">\(-\infty\)</span> to <span class="math notranslate nohighlight">\(\infty\)</span>. In most applications, the filter <span class="math notranslate nohighlight">\(h\)</span> is however compact (it has a small size of N samples, also called <em>kernel size</em>) and therefore we can limit the summation within the window of samples where the filter is non-zero.</p>
<p>A similar (but still different!) concept in signal processing is <em>correlation</em></p>
<div class="math notranslate nohighlight">
\[
y(t) = \int x(\tau) h(t+\tau) d\tau \leftrightarrow y_i = \sum_{j=-\infty}^{\infty} x_j h_{i+j}
\]</div>
<p>where the filter is simply slid across the <span class="math notranslate nohighlight">\(t\)</span> axis (without being initially flipped). The main difference between convolution and correlation is therefore that one delays the input signal whilst the other anticipates it when the filter is non-symmetric to zero. As we will see later, it is important to immediately empathize also a slight difference in the jargon used in classical signal processing and deep learning: what usually we refer to as convolution in DL is what signal processing refers to as correlation. However, since in DL we do not choose the filter <span class="math notranslate nohighlight">\(h\)</span>, rather this is learned from data, if signal processing convolution was used instead of correlation, the learning algorithm would just learned the flipped version of the filter.</p>
<p>In both cases, when we convolve two signals of size <span class="math notranslate nohighlight">\(N_x\)</span> with a filter of size <span class="math notranslate nohighlight">\(N_h\)</span>, the output signal has size:</p>
<div class="math notranslate nohighlight">
\[
N_y = N_x + N_h - 1
\]</div>
<p>However, in the context of CNNs, we generally only want to consider the so-called <em>valid</em> part of the convolution, i.e., where the entire filter contributes to the computation. For this reason the output signal size becomes:</p>
<div class="math notranslate nohighlight">
\[
N_y = N_x - N_h + 1
\]</div>
<p>In the next section, we will see how we can actually make the choice of <span class="math notranslate nohighlight">\(N_y\)</span> more flexible with the help of additional tools like padding and striding.</p>
<p>Extending the concept of convolution to two- and multi-dimensional data is straightforward. This can be done by simply
sliding the filter in all dimensions and can be mathematically written (in the discrete form) as follows:</p>
<div class="math notranslate nohighlight">
\[
y_{i,j} = \sum_m \sum_l x_{ij} h_{i+m,j+l}
\]</div>
<p>Finally, another interesting thing to notice is that convolution is a linear process. Therefore we can express it as a matrix-vector multiplication where the vector identifies the input data and the filter is re-organized into a Toeplitz matrix as show in the figure below</p>
<p><img alt="CONVMTX" src="_images/convmtx.png" /></p>
<p>which means that the gradient of a convolutional operator that we need for backpropagation is just the adjoint of the matrix <span class="math notranslate nohighlight">\(\mathbf{H}^T\)</span>. This is a convolution with the flipped kernel (so truly a convolution!).</p>
</section>
<section id="why-convolution">
<h2>Why Convolution?<a class="headerlink" href="#why-convolution" title="Link to this heading">#</a></h2>
<p>A first intuitive motivation about locality of interactions, also referred to as <em>space interactions</em>
(or <em>sparse connectivity</em> or <em>sparse weights</em>), has been already provided onto why convolution blocks may represent an appealing
alternative to fully connected blocks in the context of neural networks. However, this is not the only reason why convolution blocks are so powerful and widely used nowadays when training NNs for image processing tasks.</p>
<p>Let’s start with an example. Imagine we are given a large image and a small 3x3 kernel. By sliding the kernel across the image we can still be able to detect useful local features (e.g., edges). Note that, the Machine Learning community has been aware of this for decades, and in fact many early approaches to image detection relied on hand-crafted filters that could highlight one feature of the input data over another.
The modern DL approach simply takes this paradigm one step further where the filters are learned instead of being defined upfront. Experience has further shown that deep CNNs learn initially low level features (e.g., edges), then middle level features (e.g., shapes) and finally high level features (e.g., objects).</p>
<p><img alt="HANDLEARNED" src="_images/hand_learn_filters.png" /></p>
<p>Compared to flattening the input data and applying a matrix that transforms it into the dimension of the output data (that is what a FCC would do as shown above), using convolutions with small filters can save both memory and computations. Given for example an image of size <span class="math notranslate nohighlight">\(N_{w,x} \times N_{h,x}\)</span>, a fully connected layer that produces an output of the same size requires a matrix with <span class="math notranslate nohighlight">\((N_{w,x} N_{h,x})^2\)</span> parameters and <span class="math notranslate nohighlight">\((N_{w,x} N_{h,x})^2\)</span> computations are required to obtain
the output. On the other hand, if we now consider a simple filter of size <span class="math notranslate nohighlight">\(N_{w,h} \times N_{h,h}\)</span>, the number of computations is reduced to <span class="math notranslate nohighlight">\(N_{w,x} N_{h,x} N_{w,h} N_{h,h}\)</span>.</p>
<p>The second main advantage of convolutional blocks is so-called <em>parameter sharing</em>. The same learned kernels are applied all over the input data, instead of having one filter operating on all (or part of) the input data to produce a single output component.</p>
<p>Finally, a third benefit is the <em>equivariance of convolution to translation</em>. This means that if we shift the input by <span class="math notranslate nohighlight">\(k\)</span> samples, the output will also be shifted by the same number of samples; however, the shape of the output will not change.</p>
</section>
<section id="padding-and-strides">
<h2>Padding and strides<a class="headerlink" href="#padding-and-strides" title="Link to this heading">#</a></h2>
<p>We have previously seen how applying convolution to a signal with a kernel of a given size produces an output signal of different size, either with the total or valid output size is chosen. It may be however much easier when designing a convolutional neural network to have inputs and outputs of the same size, or more in general to be free to design the size of the output independent on that of the input and filter. Two simple approaches exist:</p>
<ul>
<li><p><em>padding</em>: the input signal is padded with zeros on both sides (for 1D signals) or all sides (for ND signals) prior to convolution. This allows producing outputs that can have the same size or even larger size than the input. Let’s first look at this with an example when the output size is computed using the equation above for the valid case. We can devise a padding such that the size of the output stays the same as that of the input. This is actually easy to do once we choose the size of the filter and more specifically <span class="math notranslate nohighlight">\(N_{x,pad} = N_x + 2*pad\)</span> with <span class="math notranslate nohighlight">\(pad = (N_h-1)/2\)</span> when <span class="math notranslate nohighlight">\(N_h\)</span> is a odd number and <span class="math notranslate nohighlight">\(N_h/2\)</span> when <span class="math notranslate nohighlight">\(N_h\)</span> is a even number.</p>
<p>Moreover, apart from the obvious benefit of not having to handle outputs that keep reducing in size, padding ensures that edge values in the inputs are also used the same number of times that central values in the convolution process.</p>
</li>
</ul>
<p><img alt="PADDING" src="_images/padding.png" /></p>
<ul class="simple">
<li><p><em>strides</em>: a common approach when building convolutional neural network, as we will see when discussing popular CNN architecture, is however to gradually reduce the size of the signal (or image in 2D) whilst going deeper and deeper into the network. Two alternative ways to achieve this exist: the simplest is to couple convolutional layers that do not change the size of the input and downsampling (or pooling layers). Alternatively, one can choose to apply a special type of convolution called <em>strided convolution</em> that simply moves the filter around the input jumping (or striding) by more than a single sample at the time. Again, if we look at an example, we can observe how by doing so the size of the output is reduced by the striding factor. If we stride by a factor of two the output size will be half of the input size. As a result the output size can be written as <span class="math notranslate nohighlight">\(N_y = \lfloor (N_x - N_h) / stride + 1 \rfloor\)</span>.</p></li>
</ul>
<p><img alt="STRIDING" src="_images/striding.png" /></p>
<p>Eventually striding and padding can be used together to get for example an output that is exactly half of the size of the input in all directions. An important formula to remember when designing convolutional layers is:</p>
<div class="math notranslate nohighlight">
\[
N_y = \Bigl\lfloor \frac{N_x + 2pad - N_h}{stride} + 1 \Bigr\rfloor
\]</div>
</section>
<section id="channels">
<h2>Channels<a class="headerlink" href="#channels" title="Link to this heading">#</a></h2>
<p>We need to introduce one last key ingredient before we can define a convolutional layer. Let’s imagine we have a 3D tensor and a 3D filter; the extension of 2D convolution to 3D (or any extra dimension) is as easy as sliding the filter along the third dimension as well as the first two. However, in deep learning we generally do something different when we are dealing with convolutional networks. We define a special dimension called <em>channel</em>.</p>
<p>Imagine having a 1D signal like a seismic trace but recording both the horizontal and vertical components of the particle displacement field. One way to arrange such data is as a 2D array where one of the dimensions is the size of the trace and the other is the number of components (or channels), here two. A similar scenario may arise for 2D signals if we record for example different spectral components or for pre-stack seismic data where we record data at different angles. Here once again we will have two “classical” dimensions, say latitude and longitude or geographical location and depth and one channel dimension. For the first example this will contain the different spectral components, for the second example it will be represented by the different angles (or offsets). This is the geoscientific equivalent to natural images that are commonly used in deep learning tasks where the channel contains different colors (e.g., RGB or CMYK). In order to make ourselves already familiar with the ordering used in computational frameworks like PyTorch, a batch of training samples is usually organized as follows:</p>
<div class="math notranslate nohighlight">
\[
N_x = (N_s \times N_{ch,x} \times N_{w,x} \times N_{h,x})
\]</div>
<p>where <span class="math notranslate nohighlight">\(N_{ch,x}\)</span> is the number of input channels, whilst <span class="math notranslate nohighlight">\(N_{w,x}\)</span> and <span class="math notranslate nohighlight">\(N_{w,h}\)</span> are the width and the height of the image, respectively.</p>
<p>By defining a special dimension, we can now decide to still work with filters that slide only across the width and height axes. Such kernels will have size <span class="math notranslate nohighlight">\(N_{ch,x} \times N_{w,h} \times N_{h,h}\)</span>.
By doing so, for every step of convolution, the input and filter and multiplied and then all the values across all channels are summed together.</p>
<p><img alt="CHANNEL" src="_images/channel.png" /></p>
</section>
<section id="convolutional-layer">
<h2>Convolutional layer<a class="headerlink" href="#convolutional-layer" title="Link to this heading">#</a></h2>
<p>A convolutional layer is simply a stack of <span class="math notranslate nohighlight">\(N_{ch,y}\)</span> filters. The resulting output has therefore a shape equal to:</p>
<div class="math notranslate nohighlight">
\[
N_y = (N_s \times N_{ch,y} \times N_{w,y} \times N_{h,y})
\]</div>
<p>where <span class="math notranslate nohighlight">\(N_{w,y}\)</span> and <span class="math notranslate nohighlight">\(N_{w,y}\)</span> can be computed upfront using the formulas derived above.</p>
<p><img alt="CONVLAYER" src="_images/convlayer.png" /></p>
<p>Note that a convolutional layer contains trainable parameters both in the form of the coefficients of the various filters and
a vector of biases <span class="math notranslate nohighlight">\(\mathbf{b}=[b_1, b_2,...,b_{N_{ch,y}}]\)</span> where every bias is applied to a different output channel. The output can be therefore written in a compact mathematical
form as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}y = \sigma \Big( \begin{bmatrix} 
                h_1 * x + b_1 \\
                ...     \\
                h_{N_{ch,y}} * x + b_{N_{ch,y}} 
  \end{bmatrix} \Big)
\end{split}\]</div>
<p>In summary, a convolutional layer has the following number of trainable parameters:</p>
<div class="math notranslate nohighlight">
\[
N_{clay}=N_{w,h}N_{h,h}N_{ch,x}N_{ch,y} + N_{ch,y}
\]</div>
<p>For example, if <span class="math notranslate nohighlight">\(N_{ch,x}=3\)</span>, <span class="math notranslate nohighlight">\(N_{ch,y}=10\)</span>, and the filters have size <span class="math notranslate nohighlight">\(3 \times 3\)</span>, the overall number of parameters is <span class="math notranslate nohighlight">\(3\cdot3\cdot3\cdot10 + 10 =280\)</span>.</p>
<p>Moreover, as convolutional layers can be stacked similarly to what we have done with MLP layers, the following nomenclature will be used in the following when
referring to a generic layer <span class="math notranslate nohighlight">\(l\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
x:&amp;\quad N_{ch}^{[l-1]} \times N_w^{[l-1]} \times N_h^{[l-1]},\\
h:&amp;\quad N_{ch}^{[l]} \times N_{ch}^{[l-1]} \times N_w^{[l-1]} \times N_h^{[l-1]},\\
b:&amp;\quad N_{ch}^{[l]},\\
y:&amp;\quad N_{ch}^{[l]} \times N_w^{[l]} \times N_h^{[l]}
\end{aligned}
\end{split}\]</div>
</section>
<section id="convolutional-network">
<h2>Convolutional network<a class="headerlink" href="#convolutional-network" title="Link to this heading">#</a></h2>
<p>Similar to a fully connected network, a convolutional network can be easily created by putting together a certain number of convolutional layers.
Although we will see that different tasks call for different design choices, most convolutional neural networks share the following design features:</p>
<ul class="simple">
<li><p>the height and width (<span class="math notranslate nohighlight">\(N_h\)</span> and <span class="math notranslate nohighlight">\(N_w\)</span>) tends to reduce the deeper we travel into the network;</p></li>
<li><p>the number of channels (<span class="math notranslate nohighlight">\(N_{ch}\)</span>) does instead increase as function of network depth;</p></li>
<li><p>after a certain number of convolutional layers, the output of size <span class="math notranslate nohighlight">\(N_{ch}^{[l]} \times N_w^{[l]} \times N_h^{[l]}\)</span> is flattened and fed into one or more
fully connected layers and then sent into a classifier (or regressor) loss function.</p></li>
</ul>
<p><img alt="CNN" src="_images/cnn1.png" /></p>
</section>
<section id="pooling">
<h2>Pooling<a class="headerlink" href="#pooling" title="Link to this heading">#</a></h2>
<p>As we have previously mentioned in the previous section, convolutional neural networks require reducing the size of the height and width of an input image
We have already discussed that by choosing the filter size, stride and padding, the output can be either kept of the same size of the input or reduced (or increased) in size.</p>
<p>At times, it may however be better to avoid changing the size of the output directly as part of the convolution process, rather perform this in a separate step. In this section we introduce the
so-called <em>pooling</em> process, which is designed specifically to reduce the size of an input N-dimensional array by an arbitrary factor <span class="math notranslate nohighlight">\(N_p\)</span>.</p>
<p>Let’s start with an example. We are interested to take a matrix of size <span class="math notranslate nohighlight">\(N_{h,x} \times N_{w,x}\)</span> as input and produce an output of half the size (i.e., <span class="math notranslate nohighlight">\(N_{h,x}/2 \times N_{w,x}/2\)</span>.
A possible way to achieve this without purely discarding some of the values of the matrix is to select the maximum value within a sliding window of size <span class="math notranslate nohighlight">\(2 \times 2\)</span> (stride=2):</p>
<p><img alt="MAXP" src="_images/maxpooling.png" /></p>
<p>This approach is commonly referred to in the literature as <em>Max Pooling</em>. This approach can be easily extended to any other subsampling by simply extending the size of the window and stride
accordingly (i.e., using to the equations defined above used for the output sizes of a convolutional layer based on the filter size and stride). Moreover, even though less commonly used, <em>Mean Pooling</em> represent an alternative approach where the mean value inside each patch is taken
instead of the maximum.</p>
<p>Finally, it is important to observe that Pooling is done for each channel independently and that it does not contain any learnable parameter.</p>
</section>
<section id="x1-convolutions">
<h2>1x1 convolutions<a class="headerlink" href="#x1-convolutions" title="Link to this heading">#</a></h2>
<p>At this point we know how to take an input tensor with an arbitrary number of dimensions (two or more) and a given number of channels, feed it
through a convolutional layer, and obtain an output sensor with the same (or slightly different size) and a new chosen number of channels.</p>
<p>It is common practice when building convolutional neural networks to start with a small number of channels and increase it gradually as we go deeper
into the network. However, when you start stacking many of these layers the number of channels will quickly grow to a point where
<span class="math notranslate nohighlight">\(N_{ch} \rightarrow \infty\)</span>. As a consequence of this fact, also the size of the filters start to grow indefinitely. But since having deeper networks
has been shown an effective way to learn very complex mappings, we need something to be able to reduce the size of these filters at any time
we are in need for it. A simple, yet very effective approach was proposed in 2013 by <a class="reference external" href="https://arxiv.org/abs/1312.4400">Lin and coauthors</a>
where filters of size <span class="math notranslate nohighlight">\(1\times1\)</span> are used to reduce the number of channels whilst keeping the number of learnable parameter to a minimum
(any other filter with bigger depth or width will introduce more learnable parameters). The authors actually refer to this <span class="math notranslate nohighlight">\(1\times1\)</span>
convolutional layer as a specific implementation of cross-channel parametric pooling, as similar to pooling reduces the size of the input tensor over
one dimensions (channel in this case).</p>
</section>
<section id="skip-connections">
<h2>Skip connections<a class="headerlink" href="#skip-connections" title="Link to this heading">#</a></h2>
<p>As already extensively discussed in one of our previous lectures, one of the problem associated with making neural networks very deep is that of
so-called vanishing gradients. However, since deep neural networks are key to high performing models, the DL community has for long time tried to
come up with strategies that can speed up the training process (or at least avoid a slow down) in the presence of long stacks of convolutional blocks.</p>
<p>One successful idea that was proposed in 2015 by <a class="reference external" href="https://arxiv.org/abs/1512.03385v1">He and coauthors</a> under the name of <em>Residual Block</em>, where
so-called <em>skip connection</em> is introduced in a NN to take the activation of a certain layer and feed it directly to another layer further down in the computational graph.
In the figure below, we consider an example where a skip connection of 2 layers is introduced to connect the activations of layer <span class="math notranslate nohighlight">\(l\)</span> and
<span class="math notranslate nohighlight">\(l+2\)</span> (just before applying a nonlinear activation). Here the <em>connection</em> is achieved by summing the two activations.</p>
<p><img alt="SKIPCON" src="_images/skipcon.png" /></p>
<p>Mathematically we can write:</p>
<div class="math notranslate nohighlight">
\[
\textbf{a}^{[l+2]}= \sigma(\textbf{a}^{[l]}+\textbf{z}^{[l+2]})
\]</div>
<p>and we can clearly see how the information contained in <span class="math notranslate nohighlight">\(\textbf{a}^{[l]}\)</span> flows through the graph along both a longer path (i.e., main path)
and a shorter one (i.e., shortcut). Finally note that in the last 5 years or so many variations of the residual block have been introduced. For example,
one could have more or less than 2 convolutional layers (or MPLs) inside the main path. Moreover, since the size of <span class="math notranslate nohighlight">\(\textbf{a}^{[l]}\)</span> and
<span class="math notranslate nohighlight">\(\textbf{z}^{[l+2]}\)</span> may be different, an additional layer with learnable parameter may be introduced as part of the shortcut to adjust for the size of
<span class="math notranslate nohighlight">\(\textbf{a}^{[l]}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\textbf{a}^{[l+2]}= \sigma(f_\theta(\textbf{a}^{[l]})+\textbf{z}^{[l+2]})
\]</div>
<p>where <span class="math notranslate nohighlight">\(f_\theta\)</span> here could simply be a convolutional layer.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="08_gradopt1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">More on gradient-based optimization</p>
      </div>
    </a>
    <a class="right-next"
       href="11_cnnarch.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">CNNs Popular Architectures</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolution">Convolution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-convolution">Why Convolution?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#padding-and-strides">Padding and strides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#channels">Channels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-layer">Convolutional layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-network">Convolutional network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pooling">Pooling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#x1-convolutions">1x1 convolutions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-connections">Skip connections</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ashok Dahal, Modified from the Content of Matteo Ravasi, KAUST
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>