
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>More on gradient-based optimization &#8212; Machine Learning for Natural Hazards</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '08_gradopt1';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Convolutional Neural Networks" href="10_cnn.html" />
    <link rel="prev" title="Best practices in the training of Machine Learning models" href="07_bestpractice.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="README.html">
  
  
  
  
  
  
    <p class="title logo__title">Machine Learning for Natural Hazards</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="README.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Background and Refresher</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_intro.html">Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_linalg.html">Linear Algebra refresher</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_gradopt.html">Gradient-based optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_linreg.html">Linear and Logistic Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="05_nn.html">Basics of Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_nn.html">More on Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_bestpractice.html">Best practices in the training of Machine Learning models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">More on gradient-based optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_cnn.html">Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_cnnarch.html">CNNs Popular Architectures</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ashokdahal/GeoAI4Haz" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ashokdahal/GeoAI4Haz/issues/new?title=Issue%20on%20page%20%2F08_gradopt1.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/08_gradopt1.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>More on gradient-based optimization</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-of-sgd">Limitations of SGD</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ill-conditioning">Ill-conditioning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#local-minima">Local minima</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#saddle-points-and-other-flat-regions">Saddle points and other flat regions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cliffs">Cliffs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exploding-and-vanishing-gradients">Exploding and vanishing gradients</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stategies-to-improve-sgd">Stategies to improve SGD</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cooling-strategy">Cooling strategy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#momentum">Momentum</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptive-learning-rates">Adaptive learning rates</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adagrad">AdaGrad</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rmsprop">RMSProp</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adam">ADAM</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-tricks">Other tricks</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#polyak-averaging">Polyak Averaging</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-normalization">Batch Normalization</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-pre-training">Supervised pre-training</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-readings">Additional readings</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="more-on-gradient-based-optimization">
<h1>More on gradient-based optimization<a class="headerlink" href="#more-on-gradient-based-optimization" title="Link to this heading">#</a></h1>
<p>Whilst stochastic gradient descent is easy to understand, and simple to implement algorithm (as discussed in this
<a class="reference internal" href="#lectures/03_gradopt.md"><span class="xref myst">lecture</span></a>), it presents a number of shortcomings that prevent learning to be as fast and effective
as we would like it to be. In this lecture, we will discuss some of the limitations of SGD and look at alternative optimization
algorithms that have been developed in the last decade and are nowadays preferred to SGD in the process of training NNs.</p>
<section id="limitations-of-sgd">
<h2>Limitations of SGD<a class="headerlink" href="#limitations-of-sgd" title="Link to this heading">#</a></h2>
<section id="ill-conditioning">
<h3>Ill-conditioning<a class="headerlink" href="#ill-conditioning" title="Link to this heading">#</a></h3>
<p>The shape, and more specifically the curvature, of the functional that we wish to minimize affects
our ability to quickly and efficiently converge to one of its minima (ideally the global, likely one of the local). For nonlinear optimization problems, like those encountered in deep learning, this is mathematically represented by the <em>Hessian</em> matrix
(<span class="math notranslate nohighlight">\(\mathbf{H}=\frac{\partial^2 f}{\partial \boldsymbol \theta^2}\)</span>). An Hessian matrix with large conditioning number (i.e.,
ratio of the largest and smallest eigenvalues) tends to affect convergence speed of first-order (gradient-based) methods.</p>
<p>In classical optimization theory, second order methods such as the Gauss-Newton method are commonly employed to counteract
this problem. However, as already mentioned in one of our previous lectures, such methods are not yet suitable for deep learning
in that no mathematical foundations have been developed in conjunction with approximate gradients (i.e., mini-batch learning
strategy).</p>
<p>Another factor that is worth knowing about is related to the norm of the gradient <span class="math notranslate nohighlight">\(\mathbf{g}^T\mathbf{g}\)</span> through iterations.
In theory, this norm should shrink through iterations to guarantee convergence. Nevertheless, successful training may still be
obtained even if the norm does not shrink as long as the learning rate is kept small. Let’s write the second-order Taylor
expansion of the functional around the current parameter estimate <span class="math notranslate nohighlight">\(\boldsymbol \theta_0\)</span>:</p>
<div class="math notranslate nohighlight">
\[
J(\boldsymbol \theta) \approx J(\boldsymbol \theta_0) + (\boldsymbol \theta - \boldsymbol \theta_0)^T \mathbf{g} + 
\frac{1}{2} (\boldsymbol \theta - \boldsymbol \theta_0)^T \mathbf{H} (\boldsymbol \theta - \boldsymbol \theta_0)
\]</div>
<p>and evaluate it at the next gradient step <span class="math notranslate nohighlight">\(\boldsymbol \theta = \boldsymbol \theta_0 - \alpha \mathbf{g}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
J(\boldsymbol \theta_0 - \alpha \mathbf{g}) \approx J(\boldsymbol \theta_0) - \mathbf{g}^T \mathbf{g} + 
\frac{1}{2} \alpha^2 \mathbf{g}^T \mathbf{H} \mathbf{g}
\]</div>
<p>We can interpret this expression as follows: a gradient step of <span class="math notranslate nohighlight">\(- \alpha \mathbf{g}\)</span> adds the following contribution
to the cost function, <span class="math notranslate nohighlight">\(-\mathbf{g}^T \mathbf{g} + 
\frac{1}{2} \alpha^2 \mathbf{g}^T \mathbf{H} \mathbf{g}\)</span>. When this contribution is positive (i.e.,
<span class="math notranslate nohighlight">\(\frac{1}{2} \alpha^2 \mathbf{g}^T \mathbf{H} \mathbf{g} &gt; \mathbf{g}^T \mathbf{g}\)</span>), the cost function grows instead of
being reduced. Under the assumption that <span class="math notranslate nohighlight">\(\mathbf{H}\)</span> is known, we could easily choose a step-size <span class="math notranslate nohighlight">\(\alpha\)</span> that prevents this from happening. However, when the Hessian cannot be estimated, a conservative selection of the step-size is the only remedy to prevent the cost function from growing. A downside of such an approach is that the smaller the learning rate the slower the training process.</p>
</section>
<section id="local-minima">
<h3>Local minima<a class="headerlink" href="#local-minima" title="Link to this heading">#</a></h3>
<p>Whilst the focus of the previous section has been in the neighbour of <span class="math notranslate nohighlight">\(\boldsymbol \theta_0\)</span> where the functional
<span class="math notranslate nohighlight">\(J_{\boldsymbol \theta}\)</span> can be approximated by a convex function, the landscape of NN functionals is generally non-convex
and populated with a multitude of local minima. The problem of converging to the global minimum without getting stuck
in one of the local minima is a well-known problem for any non-convex optimization. An example in geophysics is represented
by waveform inversion and a large body of work has been carried out by the geophysical research community to identify
objective functions that are more well-behaved (i.e., show a large basin of attraction around the global minimum).</p>
<p>Nevertheless, getting stuck into local minima is much less of a problem when training neural networks.
This can be justified by the fact that multiple models may perform equally well on both the training and testing data.
To be more precise this relates to the concept of <em>model identifiability</em>, where a model is defined identifiable if there exist a
single set of parameters (<span class="math notranslate nohighlight">\(\boldsymbol \theta_{gm}\)</span>) that lead to optimal model performance. On the other hand, when multiple models <span class="math notranslate nohighlight">\(\{ \boldsymbol \theta_{gm}, 
\boldsymbol \theta_{lm,1}, ..., \boldsymbol \theta_{lm1,N}\)</span> perform similarly those models are said to be non-identifiable. Moreover, even when a
single model performs best, a distinction must be made between training and testing performance. As far as training performance is concerned,
this model must be that of the global minimum of the functional <span class="math notranslate nohighlight">\(\boldsymbol \theta_{gm}\)</span>. Nevertheless, the model that performs best on the testing
data may be the one obtained from any of the local minima <span class="math notranslate nohighlight">\(\boldsymbol \theta_{lm,i}\)</span> as such a model be have better generalization capabilities
than the one from the global minimum.</p>
</section>
<section id="saddle-points-and-other-flat-regions">
<h3>Saddle points and other flat regions<a class="headerlink" href="#saddle-points-and-other-flat-regions" title="Link to this heading">#</a></h3>
<p>Recent research in the field of deep learning has however revealed that multi-dimensional landscapes associated to the training of
deep neural networks may actually have much fewer local minima than we tend to believe, and the main hinder to slow training is actually
represented by saddle points (and flat regions in general). More specifically, empirically it can be shown that the ratio between saddle points and local
minima is in the order of <span class="math notranslate nohighlight">\(e^n\)</span> where <span class="math notranslate nohighlight">\(n\)</span> is the number of dimensions of the model vector <span class="math notranslate nohighlight">\(\boldsymbol \theta\)</span>.</p>
<p>The main problem associated with saddle points is similar to that of local minima: the associated gradient is <span class="math notranslate nohighlight">\(J(\boldsymbol \theta) \rightarrow 0\)</span>;
as a consequence, during training, when the trajectory of the model parameter vector
approaches a saddle point, the learning process may experience a slow down.</p>
</section>
<section id="cliffs">
<h3>Cliffs<a class="headerlink" href="#cliffs" title="Link to this heading">#</a></h3>
<p>Another potentially dangerous feature of NN landscapes is represented by steep regions where <span class="math notranslate nohighlight">\(J(\boldsymbol \theta) \rightarrow \infty\)</span>.
This may in fact lead to unstable behaviours during training as large jumps will arise in the trajectory of the model parameter vector.</p>
<p>Heuristic approaches to mitigate this problem exist, one of them is the so-called <em>gradient clipping</em> strategy where:</p>
<div class="math notranslate nohighlight">
\[
\nabla J(\theta_i) = min(\nabla J(\theta_i), th)
\]</div>
<p>where <span class="math notranslate nohighlight">\(th\)</span> is a user-defined threshold. This approach allows element-wise gradient clipping for those directions with an extremely large gradient
whilst not forcing us to lower the overall learning rate.</p>
</section>
<section id="exploding-and-vanishing-gradients">
<h3>Exploding and vanishing gradients<a class="headerlink" href="#exploding-and-vanishing-gradients" title="Link to this heading">#</a></h3>
<p>Two problems that we commonly encounter whilst training Neural Networks are the so-called exploding and vanishing gradient phenomena. Whilst we already mentioned two scenarios where either of these situations can occur, i.e., cliffs and saddle points, the shape of the functional that we wish to optimize is not the only reason for gradients to grow uncontrolled or stagnate. It is in fact the NN architecture itself that sometimes may give rise to such phenomena.</p>
<p>To provide some intuition, let’s consider a matrix of weights <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> and apply it N times recursively to a certain input
(where for simplicity we ignore the nonlinear activation functions):</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}=\mathbf{W}^N\mathbf{x}
\]</div>
<p>If we assume <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> to be symmetric for simplicity and express it using
its eigendecomposition</p>
<div class="math notranslate nohighlight">
\[
\mathbf{W}=\mathbf{V} \boldsymbol \Sigma \mathbf{V}^{-1}
\]</div>
<p>the resulting output vector <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> can be equivalently written as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbf{y} &amp;= \mathbf{V} \boldsymbol \Sigma \mathbf{V}^{-1} \mathbf{V} \boldsymbol \Sigma \mathbf{V}^{-1} ... \mathbf{V} \boldsymbol \Sigma \mathbf{V}^{-1} \mathbf{x} \\
&amp;= \mathbf{V} \boldsymbol \Sigma^N \mathbf{V}^{-1} \mathbf{x}
\end{aligned}
\end{split}\]</div>
<p>where we have used here the property of eigendecomposition, <span class="math notranslate nohighlight">\(\mathbf{V}^{-1} \mathbf{V} = \mathbf{I}\)</span>. Note that since
the matrix of eigenvalues is raised to the power of N, when N is large we will experience the following phenomena:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\lambda_i &gt; 1 \rightarrow\)</span> exploding gradient;</p></li>
<li><p><span class="math notranslate nohighlight">\(\lambda_i &lt; 1 \rightarrow\)</span> vanishing gradient;</p></li>
</ul>
<p>Note that the scenario discussed here does not manifest itself when training feed forward networks, whilst it is much more relevant in the context of recurrent neural networks as the same weights are repeatedly applied to the input
as it flows through the computational graph. We defer a more extensive discussion of this phenomenon to this <a class="reference internal" href="#lectures/XX.md"><span class="xref myst">lecture</span></a>.</p>
</section>
</section>
<section id="stategies-to-improve-sgd">
<h2>Stategies to improve SGD<a class="headerlink" href="#stategies-to-improve-sgd" title="Link to this heading">#</a></h2>
<p>After looking at some of the problems that we should be aware of when training NNs (note that some of them can be
easily overcome as we will see in the following, whilst others are outstanding and do not have a simple solution), let’s look back
at the SGD algorithm and consider a number of improvements that can lead to both faster and more stable training.</p>
<p>We remember from our previous <a class="reference internal" href="#lectures/03_gradopt.md"><span class="xref myst">lecture</span></a>, that the optimization step of SGD is simply composed of two steps:</p>
<ul class="simple">
<li><p>compute the gradient of the cost function with respect to the free-parameters, obtained via back-propagation</p></li>
<li><p>apply a scaled step, dictated by the learning rate <span class="math notranslate nohighlight">\(\alpha\)</span>.</p></li>
</ul>
<section id="cooling-strategy">
<h3>Cooling strategy<a class="headerlink" href="#cooling-strategy" title="Link to this heading">#</a></h3>
<p>The most basic version of SGD uses a constant learning rate. However, a learning rate that may be optimal at the start of training and lead to fast convergence towards one of the minima of the cost function, may lead to unstable behaviour at later iterations.</p>
<p>A question arises: given a gradient telling us where to move in the NN functional landscape, can we do something smart with the
learning rate to reach the minimum faster. A common approach usually referred to as <em>cooling strategy</em> or <em>learning rate scheduling</em>, where the learning rate is not kept fixed through epochs. Instead, the learning rate is slowly reduced as epochs progress allowing the trajectory of the free-parameters to not fluctuate too much as it progresses towards a valley.</p>
<p><img alt="COOLING" src="_images/cooling.png" /></p>
<p>Many alternative approaches to LR scheduling exist. However, to be effective, they must respect the following conditions:</p>
<div class="math notranslate nohighlight">
\[
\sum_i \alpha_i = \infty, \; \sum_i \alpha_i^2 &lt; \infty'
\]</div>
<p>or, in words, the learning rate should reduce slowly as iterations progress.</p>
<p>One common approach uses a linearly decaying LR for the first <span class="math notranslate nohighlight">\(\tau\)</span> iterations, followed by a constant LR:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\alpha_i = (1-\beta) \alpha_0 + \beta \alpha_\tau \qquad i&lt;\tau\\
&amp;\alpha_i = \alpha_\tau \qquad i\ge\tau
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta=i/\tau\)</span>. As a rule of thumb, <span class="math notranslate nohighlight">\(\tau \approx 100 N_{epochs}, \alpha_\tau = \alpha_0/100\)</span>, whilst the choice
of <span class="math notranslate nohighlight">\(\alpha_0\)</span> is problem dependent and chosen by monitoring the first few iterations.</p>
<p><img alt="PWLR" src="_images/piecewiselr.png" /></p>
<p>Alternative approaches can either apply a fixed decay (i.e., exponential) or choose to reduce the LR when the training (or validation) metric has not decreased for a number of epochs.</p>
</section>
<section id="momentum">
<h3>Momentum<a class="headerlink" href="#momentum" title="Link to this heading">#</a></h3>
<p>Another commonly used strategy aimed at improving the convergence of SGD is called <em>Momentum</em> and dates back to the 60s and the
seminal works of Polyak and Nesterov in the area of mathematical optimization. The idea of momentum is rather simple, yet very effective. It is based on the idea of using information not only from the current gradient but also from past gradients when making a step. More specifically, the step is based on an exponentially decaying moving average of the past gradients created during iterations.</p>
<p><img alt="MOMENTUM" src="_images/momentum.png" /></p>
<p>The motivation behind using multiple gradients is to use the knowledge about the landscape shape accumulated through time in
the proximity of the current parameters to make a more informed decision on where to move. This can generally help dealing with
poorly conditioned modelling matrices in linear optimization and poorly conditioned Hessian matrices in nonlinear optimization.
Intuitively, momentum can be understood as some sort of medium resistance or inertia when moving down a valley which slows down the trajectory and keeps it close to the axes of the ellipses of the functional (or its linearization around the current position). This physical interpretation is actually used when defining SGD with momentum as a vector <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> (where v stands for velocity) is introduced:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{v}_{i+1} = \gamma \mathbf{v}_i - \mathbf{g}_{i+1} = \gamma \mathbf{v}_i - \frac{\alpha}{N_b} \sum_{j=1}^{N_b} \nabla \mathbf{L}_j
\]</div>
<p>and the update becomes:</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol\theta_{i+1} = \boldsymbol\theta_{i} + \mathbf{v}_{i+1}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma \in [0, 1)\)</span> is the momentum term. If we write explicitly the first three iterates of the velocity vector:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\mathbf{v}_0 = - \alpha \mathbf{g}_0\\
&amp;\mathbf{v}_1 = \gamma \mathbf{v}_0 - \alpha \mathbf{g}_1 =  - \gamma \alpha \mathbf{g}_0 - \alpha \mathbf{g}_1 \\
&amp;\mathbf{v}_2 = \gamma \mathbf{v}_1 - \alpha \mathbf{g}_2 = 
- \gamma^2 \alpha \mathbf{g}_0 - \gamma \alpha \mathbf{g}_1 - \alpha \mathbf{g}_2
\end{aligned}
\end{split}\]</div>
<p>we notice that the momentum tells us how quickly the contribution of the previous gradients should decay. With <span class="math notranslate nohighlight">\(\alpha=0\)</span> we are back to the standard SGD algorithm, whilst with <span class="math notranslate nohighlight">\(\alpha \rightarrow 1\)</span> we take into account the entire history of gradients. More commonly used values of momentum are <span class="math notranslate nohighlight">\(\alpha=0.5/0.9/0.99\)</span> which can also be combined with a warming strategy (i.e., start from 0.5 and increase through iterations all the way to 0.99). This is a similar strategy (even though in opposite direction) to the one we previously discussed for the learning rate, even though it is known to impact the learning process to a lesser extent.</p>
<p>Based on what we wrote above for the first three iterates, we can easily conclude that:</p>
<ul class="simple">
<li><p>if <span class="math notranslate nohighlight">\(\mathbf{g}_i \approx \mathbf{g}_{i-1} \approx \mathbf{g}_{i-2}\)</span> (where the sign <span class="math notranslate nohighlight">\(\approx\)</span> is used here to
indicate a vector with approximately the same direction), the gradients’ sum constructively leading to higher momentum and therefore a faster trajectory</p></li>
<li><p>if <span class="math notranslate nohighlight">\(\mathbf{g}_i \ne \mathbf{g}_{i-1} \ne \mathbf{g}_{i-2}\)</span> (where the sign <span class="math notranslate nohighlight">\(\ne\)</span> is used here to
indicate a vector with different directions), the gradients’ sum destructively leading to lower momentum and therefore a slower trajectory</p></li>
</ul>
<p>Finally, an even smarter approach would require us not only to accumulate past gradients but also to look ahead of time
so that we could slow down the trajectory if the landscape is about to change curvature (i.e., slow up). This
requires a slight modification of the momentum term, referred to as <em>Nesterov momentum</em>:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{v}_{i+1} = \gamma \mathbf{v}_i - \frac{\alpha}{N_b} \sum_{j=1}^{N_b} \nabla \mathbf{L}_j(f_{\theta+\gamma \mathbf{v}_i}(\mathbf{x}_i), y_i)
\]</div>
<p>where the main change here is represented by the fact that the loss function (<span class="math notranslate nohighlight">\(\mathbf{L}\)</span>), and therefore, the gradient is
evaluated at location <span class="math notranslate nohighlight">\(\theta+\gamma \mathbf{v}_i\)</span> rather than at the current one. Here, <span class="math notranslate nohighlight">\(\gamma \mathbf{v}_i\)</span> represents
a correction factor to the standard method of momentum. In classical optimization (i.e., for batched gradient descent), this small change provides an improvement in the rate of convergence from <span class="math notranslate nohighlight">\(\mathcal{O}(1/i)\)</span> to <span class="math notranslate nohighlight">\(\mathcal{O}(1/i^2)\)</span>. Note that this is however not always the case when using stochastic gradient descent.</p>
</section>
<section id="adaptive-learning-rates">
<h3>Adaptive learning rates<a class="headerlink" href="#adaptive-learning-rates" title="Link to this heading">#</a></h3>
<p>Up until now, we have introduced some modifications to the standard SGD algorithm that globally change the scaling of the
gradient (also referred to as learning rate). However, if we believe that directions of sensitivity of the functional should be axis aligned, different learning rates should be used for the different parameters we wish to optimize for. More specifically a small LR should be preferred for those directions associated with large eigenvalues of the local Hessian whilst a large LR should be used for the other directions that associated with small eigenvalues.</p>
<p>The <em>delta-bar-delta</em> algorithm of Jacobs (1988) represents an early heuristic approach to automatically adapting
learning rates of individual parameters. It is based on this simple rule:</p>
<ul class="simple">
<li><p>if <span class="math notranslate nohighlight">\(sign\{g_{i+1}^j\} = sign\{g_{i}^j\}\)</span>, increase LR</p></li>
<li><p>if <span class="math notranslate nohighlight">\(sign\{g_{i+1}^j\} \ne sign\{g_{i}^j\}\)</span>, decrease LR</p></li>
</ul>
<p>where <span class="math notranslate nohighlight">\(j\)</span> refers here to the j-th component of the gradient vector.</p>
<p>However, in the last decade a large variety of optimizers have appeared in the literature mostly focusing on this
particular aspect of training, i.e. parameter-dependent learning rate. We will go through some of the most popular ones
that have revolutionized the way we train NNs nowadays.</p>
<section id="adagrad">
<h4>AdaGrad<a class="headerlink" href="#adagrad" title="Link to this heading">#</a></h4>
<p>This optimizer scales the gradient vector by the inverse of the square root of the sum of all historical squared
values of the gradient.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\mathbf{g}_{i+1} = \frac{1}{N_b} \sum_{j=1}^{N_b} \nabla \mathbf{L}_j\\
&amp;\mathbf{r}_{i+1} = \mathbf{r}_i + \mathbf{g}_{i+1} \cdot \mathbf{g}_{i+1} \\
&amp;\Delta \boldsymbol\theta_{i+1} = -\frac{\alpha}{\delta + \sqrt{\mathbf{r}_{i+1}}} \cdot \mathbf{g}_{i+1} \\
&amp;\boldsymbol\theta_{i+1} = \boldsymbol\theta_{i} + \Delta \boldsymbol\theta_{i+1}
\end{aligned}
\end{split}\]</div>
<p>where the vector <span class="math notranslate nohighlight">\(\mathbf{r}\)</span> contains a running sum of the element-wise square gradients
(with <span class="math notranslate nohighlight">\(\mathbf{r}_0=0\)</span>), <span class="math notranslate nohighlight">\(\cdot\)</span> and <span class="math notranslate nohighlight">\(\sqrt{\;}\)</span> represent the element-wise multiplication of two vectors and
square root, respectively. Finally, <span class="math notranslate nohighlight">\(\delta=10^{-6}\)</span> is used as stabilizer to avoid division by zero.</p>
<p>If we look at the learning rate of AdaGrad, it is clear that this is parameter dependent and more importantly, it is
a function of the norm of the past gradients. Therefore, parameters associated with large gradients will experience
a rapid decrease in their associated LR, whilst parameters with small gradients will have an increase of the LR
through iterations.</p>
<p>The effect of such adaptive LR, is that the trajectory of the parameters will show greater
progress over gently sloped directions of the landscape. Nevertheless, it has been reported in the literature that a
main drawback of AdaGrad is that this effect is too strong, leading to a premature decrease of the LR in those
directions with large gradients and therefore an overall slow learning process.</p>
</section>
<section id="rmsprop">
<h4>RMSProp<a class="headerlink" href="#rmsprop" title="Link to this heading">#</a></h4>
<p>A modified version of AdaGrad particularly suited for nonconvex optimization where the gradient accumulation
(i.e., <span class="math notranslate nohighlight">\(\mathbf{r}\)</span> vector) is exponentially weighted on a moving window. The idea behind is that for NN training it may take a large number of gradient steps to converge to a satisfactory solution, and therefore it is important for the LR not to decrease too fast in the first few hundred steps. In mathematical terms, a single change is needed to the AdaGrad equations, namely:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{r}_{i+1} = \rho \mathbf{r}_i + (1-\rho)\mathbf{g}_{i+1} \cdot \mathbf{g}_{i+1} \\
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\rho\)</span> represents the decay rate in the accumulation of past gradients. RMSProp, which was proposed by
Geoffrey Hinton during a Coursera class, is shown to be one of the best-in-class optimizers for NN training and it
is widely adopted by the DL community.</p>
</section>
<section id="adam">
<h4>ADAM<a class="headerlink" href="#adam" title="Link to this heading">#</a></h4>
<p>ADAM stands for Adaptive Moments and it is a variant of RMSProp that further includes Momentum. Nowadays, ADAM
is by far the most popular optimizer in the training of deep NNs.</p>
<p>Two key changes have been introduced in the ADAM algorithm when compared to RMSProp:</p>
<ul class="simple">
<li><p>Momentum is applied via an estimate of the first-order momentum plus an exponential decay and used in spite of
pure gradients in the parameter update step;</p></li>
<li><p>A bias correction is included to take into account initialization.</p></li>
</ul>
<p>The algorithm can be written as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\mathbf{g}_{i+1} = \frac{1}{N_b} \sum_{j=1}^{N_b} \nabla \mathbf{L}_j\\
&amp;\mathbf{v}_{i+1} = \rho_1 \mathbf{v}_i + (1-\rho_1)\mathbf{g}_{i+1} \leftarrow velocity \; term \\
&amp;\mathbf{r}_{i+1} = \rho_2 \mathbf{r}_i + (1-\rho_2)\mathbf{g}_{i+1} \cdot \mathbf{g}_{i+1}  \leftarrow scaling \; term \\
&amp;\hat{\mathbf{v}}_{i+1} = \frac{\mathbf{v}_{i+1}}{1-\rho_1^{i+1}} \leftarrow bias \; correction \\
&amp;\hat{\mathbf{r}}_{i+1} = \frac{\mathbf{r}_{i+1}}{1-\rho_2^{i+1}} \leftarrow bias \; correction \\
&amp;\Delta \boldsymbol\theta_{i+1} = -\frac{\alpha}{\delta + \sqrt{\hat{\mathbf{r}}_{i+1}}} \cdot \hat{\mathbf{v}}_{i+1}\\
&amp;\boldsymbol\theta_{i+1} = \boldsymbol\theta_{i} + \Delta \boldsymbol\theta_{i+1}
\end{aligned}
\end{split}\]</div>
<p>where, once again, a number of hyperparameters are introduced. These are the stabilizer, <span class="math notranslate nohighlight">\(\delta=10^{-6}\)</span>, and two
decay rates (<span class="math notranslate nohighlight">\(\rho_1\)</span> and <span class="math notranslate nohighlight">\(\rho_2\)</span>).</p>
<p>To conclude, we have first introduced simpler optimizers and subsequently built complexity in terms of both momentum and
parameter-dependent learning, there is no universal winner. Although both momentum and adaptive LR do clearly seem
to be beneficial to the training on NNs, it is not always the case that ADAM provides the best results both in
terms of robustness and convergence speed. It is therefore important to be aware of the different optimizers that
are available in the DL arsenal and identify the best based on the task at end. In other words, the choice of the
optimizer can usually represent one of those hyperparameters that ML practitioners need to evaluate and select
when developing a new ML pipeline.</p>
</section>
</section>
<section id="other-tricks">
<h3>Other tricks<a class="headerlink" href="#other-tricks" title="Link to this heading">#</a></h3>
<p>In the following, we report a few other practical tricks that can be used when training NNs to further
improve the learning capabilities of our optimizer (no matter what optimizer has been selected).</p>
<section id="polyak-averaging">
<h4>Polyak Averaging<a class="headerlink" href="#polyak-averaging" title="Link to this heading">#</a></h4>
<p>When training a NN, the most common approach is to select the last iterate (<span class="math notranslate nohighlight">\(\boldsymbol\theta_{N_{it}}\)</span>) where
<span class="math notranslate nohighlight">\(N_{it}\)</span> is the overall number of iterations and use it at inference stage. Nevertheless, given the highly nonconvex
optimization problem that we are required to solver, it is logical to expect that perhaps the last estimate of
model parameters is not the best. Let’s for example imagine that towards the end of the training process we are approaching a (local or global) minimum. However, our trajectory is bouncing all around the valley:</p>
<p><img alt="POLYAK" src="_images/Polyak.png" /></p>
<p>A simple approach to mitigate this effect is to average over the last <span class="math notranslate nohighlight">\(N\)</span> iterations:</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol\theta = \frac{1}{N} \sum_{i=0}^{N-1} \boldsymbol\theta_{N_{it}-i}
\]</div>
<p>This averaging acts as a denoising process that takes away some of the fluctuations and makes the optimization
process less sensitive to the last step.</p>
</section>
<section id="batch-normalization">
<h4>Batch Normalization<a class="headerlink" href="#batch-normalization" title="Link to this heading">#</a></h4>
<p>This is a very recent advancement in the field of DL, from the seminal work of Ioffe and Szegedy (2015). It has been shown
to be particularly beneficial to the training of very deep neural networks.</p>
<p>Let’s first take a look at what happens during the training process if we do not include batch normalization. As
previously discussed, given the gradient <span class="math notranslate nohighlight">\(\partial J / \partial \boldsymbol \theta\)</span>, at every step of the optimization
process all the parameters (weights and biases) in the different layers of a NN are simultaneously updated. This
goes against the “theoretical assumption” that the optimization process should update one parameter at the time (which
is however too expensive and therefore unfeasible). As a consequence of the fact that all free-parameters are updated
together is that second order updates are introduced or, in other words, the statistical distribution of various parameters
across the layers of the NN are modified. This is commonly referred to as <em>internal covariate shift</em>.</p>
<p><em>Batch normalization</em> use a general way to reparametrize every NN, which reduces the need for coordination across many
layers during an update (making the process of updating all parameters at the same time more stable). It is simply
implemented by modifying the output of a layer (or all the layers) at training time as follows:</p>
<p><img alt="BATCHNORM" src="_images/batchnorm.png" /></p>
<p>where a re-normalization process is applied to every row of the output matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and it is directly based on the local statistics (mean and standard deviation) of the output of the layer. The overall forward and backward passes remain unchanged with the simple difference that the network is now operating on the re-normalized output <span class="math notranslate nohighlight">\(\mathbf{A}'\)</span> instead of the original one <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>.</p>
<p>The implications of such an additional step of re-normalization are that now the activations are distributed as <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span> throughout the entire training process. By doing so, the optimization algorithm is discouraged to propose an update that simply acts constantly over the mean or the standard deviation of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>.</p>
<p>At testing time, the mean and standard deviation (<span class="math notranslate nohighlight">\(\boldsymbol \mu\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol \sigma\)</span>) are usually fixed and taken from a
running mean computed during training time.</p>
<p>In practice, however, batch normalization includes an extra step where instead of forcing the mean and standard deviation
of each layer to be fixed, these parameters are learned to make the units of the network more expressive. This is simply
accomplished by defining the output <span class="math notranslate nohighlight">\(\mathbf{A}''\)</span> as:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{A}'' = \gamma \mathbf{A}' + \beta
\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> are also learned alongside the weights and biases of the network. Finally, since the bias is now induced by <span class="math notranslate nohighlight">\(\beta\)</span> a common recommendation when using batch normalization is to avoid adding a learnable bias to the layer of the network.</p>
</section>
<section id="supervised-pre-training">
<h4>Supervised pre-training<a class="headerlink" href="#supervised-pre-training" title="Link to this heading">#</a></h4>
<p>So far, we have talked about optimizing the free-parameters of a neural network starting from a random initialization of such
parameters and using all the available data to get the best estimate of such parameters. We have also briefly mentioned that
transfer learning, a technique that uses a pre-trained network on a different set of data and possible different task and fine-tunes it on the task and data at hand, as a way to speed-up the training process as well as get around to the fact that sometimes we have access to a small amount of labelled data.</p>
<p>Another interesting technique that can be used to ease the learning capabilities of a NN is called <em>pre-training</em> or <em>greedy training</em>. Two alternative approaches are generally taken:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol \theta_0\)</span> (selected at random) <span class="math notranslate nohighlight">\(\rightarrow\)</span> Simple task: <span class="math notranslate nohighlight">\(\tilde{\boldsymbol \theta}\)</span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> Hard task: <span class="math notranslate nohighlight">\(\tilde{\boldsymbol \theta'}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol \theta^1_0\)</span> (selected at random) <span class="math notranslate nohighlight">\(\rightarrow\)</span> Simple network: <span class="math notranslate nohighlight">\(\tilde{\boldsymbol \theta^1}, \boldsymbol \theta^2_0\)</span>
<span class="math notranslate nohighlight">\(\rightarrow\)</span> Complex network: <span class="math notranslate nohighlight">\(\tilde{\boldsymbol \theta^1}, \tilde{\boldsymbol \theta^2}\)</span></p></li>
</ul>
<p>where in the latter case a common approach is to fix the hidden layers and discard the output layer after the first training process, add a number of extra layers to make the network deeper and continue training those layers alone. However, since N independent optimizations generally do not provide the overall optimal solution, a final fine-tuning step may be required.</p>
</section>
</section>
</section>
<section id="additional-readings">
<h2>Additional readings<a class="headerlink" href="#additional-readings" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>A <a class="reference external" href="https://github.com/jettify/pytorch-optimizer">great resource</a> containing references (and Pytorch implementations) of more than 20 optimizers. This may be a good starting point if interest to experiment with different optimizers in both classical optimization and training of NNs.</p></li>
<li><p>Another great <a class="reference external" href="https://github.com/labmlai/annotated_deep_learning_paper_implementations">resource</a> with step-by-step implementations of
some popular optimizers and networks.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="07_bestpractice.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Best practices in the training of Machine Learning models</p>
      </div>
    </a>
    <a class="right-next"
       href="10_cnn.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Convolutional Neural Networks</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-of-sgd">Limitations of SGD</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ill-conditioning">Ill-conditioning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#local-minima">Local minima</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#saddle-points-and-other-flat-regions">Saddle points and other flat regions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cliffs">Cliffs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exploding-and-vanishing-gradients">Exploding and vanishing gradients</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stategies-to-improve-sgd">Stategies to improve SGD</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cooling-strategy">Cooling strategy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#momentum">Momentum</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptive-learning-rates">Adaptive learning rates</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adagrad">AdaGrad</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rmsprop">RMSProp</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adam">ADAM</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-tricks">Other tricks</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#polyak-averaging">Polyak Averaging</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-normalization">Batch Normalization</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-pre-training">Supervised pre-training</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-readings">Additional readings</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ashok Dahal, Modified from the Content of Matteo Ravasi, KAUST
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>