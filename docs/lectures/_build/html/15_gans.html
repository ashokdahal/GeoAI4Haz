
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Generative Adversarial Networks (GANs) &#8212; Machine Learning for Natural Hazards</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '15_gans';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="README.html">
  
  
  
  
  
  
    <p class="title logo__title">Machine Learning for Natural Hazards</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="README.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Background and Refresher</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_intro.html">Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_linalg.html">Linear Algebra refresher</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_gradopt.html">Gradient-based optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_linreg.html">Linear and Logistic Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="05_nn.html">Basics of Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_nn.html">More on Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_bestpractice.html">Best practices in the training of Machine Learning models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="08_gradopt1.html">More on gradient-based optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_cnn.html">Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_cnnarch.html">CNNs Popular Architectures</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ashokdahal/GeoAI4Haz" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ashokdahal/GeoAI4Haz/issues/new?title=Issue%20on%20page%20%2F15_gans.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/15_gans.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Generative Adversarial Networks (GANs)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gans-groundbreaking-idea">GANs groundbreaking idea</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematics-of-gans">Mathematics of GANs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-of-gans">Training of GANs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mode-collapse">Mode collapse</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vanishing-gradients">Vanishing gradients</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions-to-unstable-training">Solutions to unstable training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-gans">Conditional GANs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#domain-translation-with-gans">Domain translation with GANs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#paired-training">Paired training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unpaired-training">Unpaired training</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-readings">Additional readings</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="generative-adversarial-networks-gans">
<h1>Generative Adversarial Networks (GANs)<a class="headerlink" href="#generative-adversarial-networks-gans" title="Link to this heading">#</a></h1>
<p>A fundamentally new way of approaching generative modelling has been proposed by <a class="reference external" href="https://arxiv.org/abs/1406.2661">Goodfellow and co-authors</a> in 2014.
Similar to VAEs, Generative Adversarial Networks (GANs) can learn a distribution from some training samples, or more precisely thy can learn to sample
from the underlying, unknown distribution. This family of NNs are revolutionary in that they can produce very high quality (i.e., extremely realistic)
samples compared to predecessor models at similar computational cost.</p>
<p>Whilst the core application of GANs (and pretty much any generative model in deep learning) has been computer vision (i.e., natural images and portraits
of people in particular), their use in geoscience has also recently provided us with new ways of generating “new” samples that can easily outperform state-of-the-art
geostatistical tools. This is very appealing in applications like reservoir modelling as geologists and reservoir engineers are nowadays usually tasked to work with
multiple realizations of the subsurface and provide probabilistic estimates to support the subsequent decision making process. A few examples of early
applications of GANs in geoscience are:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1704.03225">Mosser et al.</a>, Reconstruction of three-dimensional porous media using generative adversarial neural networks</p></li>
<li><p><a class="reference external" href="https://link.springer.com/article/10.1007/s12182-019-0328-4">Zhang et al.</a>, Generating geologically realistic 3D reservoir facies models using deep learning of sedimentary architecture with generative adversarial networks</p></li>
<li><p><a class="reference external" href="https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020JB020077?af=R">Wang et al.</a>, SeismoGen: Seismic Waveform Synthesis Using GAN With Application to Seismic Data Augmentation</p></li>
<li><p>…</p></li>
</ul>
<p>We will begin by discussing the main application of GANs, i.e. pure unconditional generation. Later, we will however see that
recent modifications of GANs have allowed performing conditional generation (e.g., generate facies model conditioned to well information) as well
as domain transformation (e.g., from seismic to reflectivity, from facies to petrophysical parameters). The latter has been shown to outperform traditional
supervised learning workflows based for example on UNet architectures.</p>
<section id="gans-groundbreaking-idea">
<h2>GANs groundbreaking idea<a class="headerlink" href="#gans-groundbreaking-idea" title="Link to this heading">#</a></h2>
<p>Let’s start by looking at the basic idea of GANs with a schematic drawing of the network architecture (or, as we will soon become familiar with, we should say
the network architectures as we will be dealing with two networks!):</p>
<p><img alt="GAN" src="_images/gan.png" /></p>
<p>A GAN model is composed of two networks, namely:</p>
<ul class="simple">
<li><p>Generator (<span class="math notranslate nohighlight">\(g_\theta\)</span>): takes an input vector <span class="math notranslate nohighlight">\(\mathbf{z} \in \mathbb{R}^{N_l}\)</span> randomly sampled for a given distribution
(e.g., <span class="math notranslate nohighlight">\(\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\)</span>) and produces an output vector <span class="math notranslate nohighlight">\(\hat{\mathbf{x}} \in \mathbb{R}^{N_f}\)</span>
that should should belong to the underlying probability distribution of the training samples, <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span>).
To achieve this task, the generator is not allowed direct access to the training samples <span class="math notranslate nohighlight">\(\mathbf{x}^{&lt;i&gt;}\)</span>. On the other hand, it relies
on the discriminator for feedback.</p></li>
<li><p>Discriminator (<span class="math notranslate nohighlight">\(d_\phi\)</span>): takes both real samples <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and fake samples <span class="math notranslate nohighlight">\(\hat{\mathbf{x}}\)</span> (the latter coming from the generator)
and tries to classify them. Its goal is to discriminate between true and fake samples, or in other words to identify which samples are coming from
the generator.</p></li>
</ul>
<p>A classical example from the original paper is that the generator is a painting forger, whilst the discriminator is a painting critic. It is obvious here
that these two networks must compete with each other, if one achieves its goal the other would have failed and vice-versa. As we will see later, this is
what makes GANs successful but also hard to train. Moreover, whilst training is performed in parallel, it is worth noticing that the generator network is what
ultimately we care about (to be able to create realistic samples), whilst the discriminator is an auxiliary network that will be discarded after training.</p>
</section>
<section id="mathematics-of-gans">
<h2>Mathematics of GANs<a class="headerlink" href="#mathematics-of-gans" title="Link to this heading">#</a></h2>
<p>Before we delve into the mathematical framework of GANs, let’s take a more detailed look at the two networks and their training process. First, the generator:</p>
<p><img alt="GANGENERATOR" src="_images/gen.png" /></p>
<p>and the discriminator:</p>
<p><img alt="GANDISCRIMINATOR" src="_images/disc.png" /></p>
<p>As previously explained, the generator is updated solely based on the samples it generates. This is not done in a direct form, rather through the feedback
of the discriminator. As the generator tries to fool the discriminator, the discriminator is provided with true labels during the generator training phase.
On the other hand, the discriminator is fed with both true and fake samples and their correct corresponding label. Its task is therefore to perform a correct classification,
which, if successful, will prevent the generator from producing realistic fake samples. Note that since we want the discriminator to perform a binary classification task the activation
of the last layer must be chosen to be a sigmoid function.</p>
<p>Let’s try to put down into equations this training process. Given that we are dealing with a binary classification problem, the obvious choice for the loss function
is the commonly used binary cross entropy (BCE) loss. Starting from the generator:</p>
<div class="math notranslate nohighlight">
\[
\mathscr{L}(\hat{\mathbf{x}}, \hat{\mathbf{y}}=1) = BCE(d_\phi(g_\theta(\mathbf{z})), \hat{\mathbf{y}}=1) = -log(d_\phi(g_\theta(\mathbf{z})))
\]</div>
<p>which is minimum for <span class="math notranslate nohighlight">\(g_\theta(d_\phi(\mathbf{z}))=1\)</span> (i.e., when the generator has been able to fool the discriminator), and maximum for
<span class="math notranslate nohighlight">\(g_\theta(d_\phi(\mathbf{z}))=0\)</span> (i.e., when the discriminator recognizes the creation of the generator).</p>
<p>For the discriminator we must consider two cases. The first one is associated with the generator:</p>
<div class="math notranslate nohighlight">
\[
\mathscr{L}(\hat{\mathbf{x}}, \hat{\mathbf{y}}=0) = BCE(d_\phi(g_\theta(\mathbf{z})), \hat{\mathbf{y}}=0) = -log(1-d_\phi(g_\theta(\mathbf{z})))
\]</div>
<p>which is minimum for <span class="math notranslate nohighlight">\(g_\theta(d_\phi(\mathbf{z}))=0\)</span> (i.e., when the discriminator recognizes the creation of the generator), and maximum for
<span class="math notranslate nohighlight">\(g_\theta(d_\phi(\mathbf{z}))=1\)</span> (i.e., when the generator has been able to fool the discriminator). The second one is instead
associated with the true samples:</p>
<div class="math notranslate nohighlight">
\[
\mathscr{L}(\mathbf{x}, \mathbf{y}=1) = BCE(d_\phi(\mathbf{x}), \mathbf{y}=1) = -log(d_\phi(\mathbf{x}))
\]</div>
<p>which is minimum for <span class="math notranslate nohighlight">\(d_\phi(\mathbf{x})=1\)</span> (i.e., when the discriminator recognizes the true samples), and maximum for
<span class="math notranslate nohighlight">\(d_\phi(\mathbf{x})=0\)</span> (i.e., when the discriminator believes that the true samples are fake).</p>
<p>Whilst for simplicity we have analyzed these three terms separately and focused on how they can be minimized (this is also what we would do when
implementing GANs in practice), a unique <em>adversarial loss function</em> can be also defined that uniquely identifies the goal of GAN training:</p>
<div class="math notranslate nohighlight">
\[
\mathscr{L}_{adv} = E_{\mathbf{x} \sim p_x} [log(d_\phi(\mathbf{x}))] + 
E_{\mathbf{z} \sim p_z} [log(1- d_\phi(g_\theta(\mathbf{z})))]
\]</div>
<p>and the overall training problem can be written as:</p>
<div class="math notranslate nohighlight">
\[
arg \; \underset{g_\theta} {\mathrm{min}} \; \underset{d_\phi} {\mathrm{max}} \; \mathscr{L}_{adv} 
\]</div>
<p>This is interesting, as we are not simply minimizing a loss function to find the best parameters of a network, rather we are required to play a min-max
game between the generator and discriminator. This is exactly where the Adversarial part of the name GANs comes from.</p>
</section>
<section id="training-of-gans">
<h2>Training of GANs<a class="headerlink" href="#training-of-gans" title="Link to this heading">#</a></h2>
<p>Although there are various strategies to successfully train these two networks together, the most common one is to do one step of
optimization on one and one on the other in an alternating fashion. By doing so, we allow the two networks to competitively learn together
their own task whilst trying to make the other network fail on the other task.</p>
<p>In practice, the learning process of GANs can be however very unstable (and sometimes even unpredictable). A common scenario is in fact represented
by the fact that one network learns its task much faster than the other network. Depending on which of the two networks is the fast
learner, the following scenarios may arise:</p>
<ul class="simple">
<li><p>Super-discriminator (i.e., the discriminator outpaces the generator): the generator is made aware of the fact that most (if not all) of his fake samples have been identified by
the discriminator. By not knowing which of the generated samples are harder to discriminate and which ones are easier, the network cannot update its parameters
to generator more of the samples that were mislead for real and less of those that were identified as fake by the discriminator. This is the most common scenario
as the discriminator has a much easier task (binary classification) compared to that of the generator (learning a probability density function);</p></li>
<li><p>Super-generator (i.e.,the generator outpaces the discriminator): as the discriminator cannot tell apart the true from the fake samples, the generator is satisfied with what it is
producing and continues to do so. Whilst this is the ideal scenario that we wish to experience after some epochs of training, when this arises early (in the first few epochs),
it is usually a sign that the generator is producing samples that are very similar to each other instead of a representative set of samples of the underlying
distribution (so-called mode collapse).</p></li>
</ul>
<p>Now that we know how to train GANs, and that the training process may be hard, let’s discuss in details a number of scenarios that we may encounter during
training. After that, we will discuss a number of strategies that have been devised through out the years to minimize the risk of having unbalanced training and ultimately
a generator with poor generative capabilities.</p>
<section id="mode-collapse">
<h3>Mode collapse<a class="headerlink" href="#mode-collapse" title="Link to this heading">#</a></h3>
<p>Let’s consider the following multi-modal 1-dimensional distribution:</p>
<p><img alt="GANCOLLAPSE" src="_images/gancollapse.png" /></p>
<p>A successfully trained GAN is able to generate sample from the different modes of this distribution. However, it is common for a GAN to identify a single mode
and stick to it, generating only samples from a small part of the overall distribution. As these samples are realistic, the generator may eventually end up fooling
the discriminator losing any interest in exploring other areas of the distribution.</p>
<p>More precisely, let’s imagine that during the early stages of training the
discriminator is able to distinguish between fake and real samples for 3 of the 4 modes whilst it struggles for the remaining one. Whilst trying to fool the
discriminator, the generator realizes that and exploits its ability to fool the discriminator when sampling from one of the modes. By doing this, the generator becomes
better and better at producing realistic samples from that mode but forgets about the fact that the probability it is trying to approximate may be multi-modal.
Whilst this is a better scenario than the one depicted above (i.e., the generator is outpaced by the discriminator and cannot produce any representative sample),
mode collapse is still something we would like to avoid if possible. We will soon discuss a number of modifications to the classical GAN model that can achieve that.</p>
</section>
<section id="vanishing-gradients">
<h3>Vanishing gradients<a class="headerlink" href="#vanishing-gradients" title="Link to this heading">#</a></h3>
<p>Another problem commonly experienced whilst training GANs is represented by the arising of vanishing gradients. Let’s imagine that at the start of the training process,
the discriminator manages to get the two distribution (true and generator) far apart. In this scenario, the gradient of the BCE loss tends to flatten and training
starts to slow down as depicted in the figure below:</p>
<p><img alt="GANVANISH" src="_images/vanishgradgan.png" /></p>
<p>In other words, once the distributions stop overlapping the chances of the generator to keep learning and producing something meaningful  drastically reduce (or at least
the learning process becomes very slow).</p>
</section>
</section>
<section id="solutions-to-unstable-training">
<h2>Solutions to unstable training<a class="headerlink" href="#solutions-to-unstable-training" title="Link to this heading">#</a></h2>
<p>In the quest of creating stable and reliable GAN models, a number of researchers have suggested that the BCE loss initially used in the
original GAN paper may be the main cause of some of the above highlighted problems. As GANs ultimate goal is that of estimate a probability distribution,
a suggestion was made by <a class="reference external" href="https://arxiv.org/abs/1701.07875">Arjovsky</a> and coauthors in 2017 to replace the BCE loss with the so-called Wasserstein loss.</p>
<p>Simply put, the Wasserstein distance, or Earth’s mover distance, is a distance function between two probability distributions that computes the amount of earth (or soil)
that needs to be moved from one probability to match another. Let’s take a look at it with an example where for simplicity we discretize two probability distributions
(i.e., we display them as histograms). In this case we can simply observe that the Wasserstein distance between such probabilities is 1 as we need to make just
one move to match them:</p>
<p><img alt="WASSER" src="_images/wasser.png" /></p>
<p>More importantly, a clear implication in choosing this loss function over BCE for the training of GANs lies in the fact that its gradient does not saturate very quickly
as two distributions are pulled far apart. This greatly eases the training process of the generator even when the discriminator is superior at the beginning of the training process.</p>
<p>In practice, when using the Wasserstein distance, the loss function of the min-max game becomes:</p>
<div class="math notranslate nohighlight">
\[
arg \; \underset{g_\theta} {\mathrm{min}} \; \underset{d_\phi} {\mathrm{max}} \; E_{\mathbf{x} \sim p_x} [d_\phi(\mathbf{x})] -
E_{\mathbf{z} \sim p_z}[d_\phi(g_\theta(\mathbf{z}))]
\]</div>
<p>and the training process remains unchanged. Finally, note in the context of Wasserstein GANs (W-GANs) the discriminator is sometimes also
called critic as its role it is not anymore to perform a classification but simply criticize the fake samples. Moreover, although the
Wasserstein loss makes training of GANs less unstable, it introduces a problem. The training of the discriminator can be affected by the
exploding gradient behaviour, due to the fact that the discriminator may not be 1-Lipschitz continuous. Various approaches have been introduced to
avoid such a situation, <em>gradient clipping</em> and <em>gradient penalty</em> are two of the most common solutions.</p>
<p>To conclude this section, it is worth mentioning that a number of other strategies have been proposed in the literature to mitigate training failures of GANs.
Whilst we will not go into the details here, we will briefly mention a couple of them:</p>
<ul class="simple">
<li><p><em>Spectral normalization</em>: another approach used to ensure that the discriminator is 1-Lipschitz continuous. As the name implies, spectral normalization
is a normalization procedure applied to each layer of the network to ensure that the spectral norm of the layer is smaller or equal to 1. It requires estimating
the largest eigenvalue of each layer and renormalizing its weight whenever they are updated. For more details, see this <a class="reference external" href="https://jonathan-hui.medium.com/gan-spectral-normalization-893b6a4e8f53">blog post</a> for more details.</p></li>
<li><p><em>Polyak averaging of the generator</em>: as discussed in this <a class="reference internal" href="08_gradopt1.html"><span class="std std-doc">lecture</span></a>, it is possible to mitigate the importance of the stopping criterion
when training GANs by averaging the parameters of the generator for a number of iterations <span class="math notranslate nohighlight">\(N_{it}\)</span> (or even epochs).</p></li>
<li><p>Pro-GAN (Progressive growing GANs): Instead of training a GAN network directly on the high-resolution output of interest, a good strategy proposed by
<a class="reference external" href="https://arxiv.org/abs/1710.10196">Karras and coauthors</a> is to start with a smaller, lower resolution version and train a small GAN. This is repeated for a number
of times by freezing the trained layers, adding more layers, and increasing the resolution of the sought output.</p></li>
</ul>
</section>
<section id="conditional-gans">
<h2>Conditional GANs<a class="headerlink" href="#conditional-gans" title="Link to this heading">#</a></h2>
<p>The original formulation of GANs aims at learning an unconditional probability distribution and sampling from it. However, in many real life scenarios we may
expect the probability distribution of our data to be somehow clustered (i.e., display a multi-modal behaviour). Let’s for example imagine that we are
provided with a number of geological models from all over the world and our goal is to teach a GAN to create new ‘fake’ models that are as realistic as possible.
Whilst all the geological models share some high-level features, it is logical to expect that some of them have more things in common then others. Let’s also assume
we are provided with such information in the form of labels, so that for each sample we also know the class it belongs to. If we were able to sample from a 2-dimensional
latent space and reproduce exactly our training samples, this is what we may observe:</p>
<p><img alt="GANGEOLOGY" src="_images/gangeol.png" /></p>
<p>It may be appealing to train a GAN that at inference time could produce samples conditionally to us choosing a specific class (or cluster) of interest. Of course,
the most straightforward approach could be to separate the training samples into <span class="math notranslate nohighlight">\(N_c\)</span> buckets and train <span class="math notranslate nohighlight">\(N_c\)</span> independent GANs. This is however very costly. A smarter approach
is to turn our generative network from unconditional to conditional, something we call conditional GAN (or c-GAN).</p>
<p>Conditional GANs present a number of distinctive features when compared to traditional GANs, which we are going to summarize here:</p>
<ul class="simple">
<li><p>Alongside a random vector <span class="math notranslate nohighlight">\(\mathbf{z} \in \mathbb{R}^{N_l}\)</span>, the generator is now also fed with a label that represents the class we wish to sample from. These two are
concatenated to each other to form a new vector <span class="math notranslate nohighlight">\(\tilde{\mathbf{z}} = [\mathbf{z}, c] \in \mathbb{R}^{N_l+1}\)</span>. Alternatively, the label can be one-hot encoded into a
vector <span class="math notranslate nohighlight">\(\mathbf{c}\)</span> and the generator is fed with <span class="math notranslate nohighlight">\(\tilde{\mathbf{z}} = [\mathbf{z}, \mathbf{c}] \in \mathbb{R}^{N_l+N_c}\)</span>. By doing so at training time, we inform the generator
that we are not just interested in producing a random sample from the distribution of the training data, rather we want a sample from a specific class. Once the network is trained,
at inference time we will have the ability to sample conditionally;</p></li>
<li><p>The discriminator is also made aware of the fact that the training data is divided into classes. And of course, this goes also for the generated samples. Similar to the generator input,
the input of the discriminator is now modified to include also the label of the true sample (or the label provided to the generator for the fake sample). Once again the vector
<span class="math notranslate nohighlight">\(\mathbf{x} is simply concatenated with either the label \)</span>c<span class="math notranslate nohighlight">\( or its one-hot encoded version \)</span>\mathbf{c}<span class="math notranslate nohighlight">\( to create a new input to the discriminator \)</span>\tilde{\mathbf{x}}$.</p></li>
</ul>
<p><img alt="CGAN" src="_images/cgan.png" /></p>
<p>Finally, what if the input of the discriminator (and/or generator) is N-dimensional. This is usually the case when working with natural images or multi-dimensional
geoscientific data (e.g., seismic data, satellite images). A simple modification of the process described above can be introduced. Instead of concatenating the label
<span class="math notranslate nohighlight">\(c\)</span> to the 1-dimensional <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> (or <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>) vector, an additional channel is added to the N-dimensional <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> (or <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>) tensor that contains the value of the label.
Similarly, when working with the one-hot encoded version of the label, <span class="math notranslate nohighlight">\(N_c\)</span> channels are added instead with one of them containing 1s (the one corresponding to the label) and all
others containing 0s.</p>
</section>
<section id="domain-translation-with-gans">
<h2>Domain translation with GANs<a class="headerlink" href="#domain-translation-with-gans" title="Link to this heading">#</a></h2>
<p>To conclude this lecture, we will discuss a slightly different application of GANs. Whilst so far we have presented GANs as statistical modelling tools for generative tasks,
it turns out they are also useful for image-to-image translation (or more broadly, for any form of <em>domain translation</em>).</p>
<p><img alt="DOMAINTRANS" src="_images/domaintransl.png" /></p>
<p>We previously mentioned this application in the context of convolutional networks and more specifically the UNet architecture. The idea is to map data from a given input domain to
a given output domain. A number of interesting applications in geoscience may benefit from this set up. For example, any geophysical processing step can be seen as a domain translation task
where we transform the input data into a new version of it. Also, we could think of using domain translation as a way to create realistic geological models from sketches or to populate them
with petrophysical properties whist starting from a pure facies skeleton.</p>
<p>In general, two scenarios may arise:</p>
<ul class="simple">
<li><p>Paired training: the training data provides us with paired combinations of samples from the two domains, e.g., <span class="math notranslate nohighlight">\(\mathbf{x}_A^{&lt;i&gt;} \leftrightarrow \mathbf{x}_B^{&lt;i&gt;} \; \forall i\)</span></p></li>
<li><p>Unpaired training: the training data comes in the form of two set of training samples, the first from domain A and the second from domain B. However, we do not know how each sample
of one domain is related to a sample of the other domain, i.e. <span class="math notranslate nohighlight">\(X_A = (\mathbf{x}_A^{&lt;1&gt;}, \mathbf{x}_A^{&lt;2&gt;}, ..., \mathbf{x}_A^{&lt;N_A&gt;})\)</span> and
<span class="math notranslate nohighlight">\(X_B = (\mathbf{x}_B^{&lt;1&gt;}, \mathbf{x}_B^{&lt;2&gt;}, ..., \mathbf{x}_B^{&lt;N_B&gt;})\)</span>.</p></li>
</ul>
<section id="paired-training">
<h3>Paired training<a class="headerlink" href="#paired-training" title="Link to this heading">#</a></h3>
<p>In 2017 <a class="reference external" href="https://arxiv.org/abs/1611.07004">Isola and coauthors</a> suggested that c-GANs could be used for paired domain translation and proposed the so called Pix2Pix network.
Mathematically speaking, whilst a traditional c-GAN aims to learn:</p>
<div class="math notranslate nohighlight">
\[
p(\mathbf{x} | \mathbf{z}, c)
\]</div>
<p>a c-GAN for domain translation will be tasked to learn:</p>
<div class="math notranslate nohighlight">
\[
p(\mathbf{x}_B | \mathbf{z}, \mathbf{x}_A)
\]</div>
<p>where the noise vector <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> can be used to sample multiple realizations conditioned on the given input <span class="math notranslate nohighlight">\(\mathbf{x}_A\)</span>. In practice, it turns out that this problem is
too constrained to allow ‘rich sampling’, so the original authors suggest to remove <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> from the inputs and use alternative approaches such as dropout if interested
to produce multi outputs.</p>
<p>The overall network architecture of Pix2Pix can be summarized as follows:</p>
<p><img alt="PIX2PIX" src="_images/pix2pix.png" /></p>
<ul class="simple">
<li><p>Generator: as the inputs and outputs of the generator share the same dimensions, the network architecture here does not need to be that of a
<code class="docutils literal notranslate"><span class="pre">decoder</span></code> like in classical GANs. More powerful architectures with skip connections, like UNet, can be used instead. Note that, as mentioned above, there
the random vector <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> is not required to be the input of the generator.</p></li>
<li><p>Discriminator: similar to c-GAN, both the true samples from the target domain, <span class="math notranslate nohighlight">\(\mathbf{x}_B\)</span>, as well as the predicted ones, <span class="math notranslate nohighlight">\(\hat{\mathbf{x}}_B\)</span> are fed to the
discriminator concatenated with their corresponding sample in the original domain, <span class="math notranslate nohighlight">\(\mathbf{x}_A\)</span>. A second modification to the usual GAN discriminator is also applied
here. Instead of using a classical discriminator that reduces the dimensionality of the output to a scalar, Pix2Pix use a special type of discriminator called <em>Patch GAN</em>.
More specifically, the discriminator produces an 2-dimensional output of size <span class="math notranslate nohighlight">\(N_d \times N_d\)</span> (where <span class="math notranslate nohighlight">\(N_d\)</span> is much smaller than
the size of the input samples, <span class="math notranslate nohighlight">\(N \times N\)</span>). This matrix contains values that are fed independently to the adversarial loss used in classical GANs. By doing
the PatchGAN discriminator tries to classify if each <span class="math notranslate nohighlight">\(N/N_d \times N/N_d\)</span> patch in an image is real or fake, providing therefore a much richer feedback to the generator.</p></li>
</ul>
<p>Apart from the network changes, Pix2Pix introduces also a modification to the original loss function of GANs:</p>
<div class="math notranslate nohighlight">
\[
\mathscr{L} = \mathscr{L}_{adv} + \lambda \mathscr{L}_{pix}
\]</div>
<p>where the first term, <span class="math notranslate nohighlight">\(\mathscr{L}_{adv}\)</span>, is the adversarial loss of choice, whilst the second term computes the error between the predicted sample in the new domain and the
corresponding true one, e.g. <span class="math notranslate nohighlight">\(MSE(\hat{\mathbf{x}}_B^{&lt;i&gt;}, \mathbf{x}_B^{&lt;i&gt;})\)</span>. As this can be interpreted as the classical loss term of a supervised learning task, Pix2Pix
does indeed trade-off between performing a classical reconstruction with pixel-wise loss and producing samples that can fool the discriminator.</p>
</section>
<section id="unpaired-training">
<h3>Unpaired training<a class="headerlink" href="#unpaired-training" title="Link to this heading">#</a></h3>
<p>As we previously mentioned, it is not always possible to have access to paired samples from the two domains. Provided access to a variety of samples from domains A and B, <em>CycleGAN</em>
was introduced by <a class="reference external" href="https://arxiv.org/abs/1703.10593">Zhu and colleagues</a> as a way to perform domain translation in this more general setup. The idea of CycleGAN is to train 2
GANs in parallel, one performing a domain translation task from A to B and the other performing a domain translation task from B to A:</p>
<p><img alt="CYCLEGAN" src="_images/cyclegan.png" /></p>
<p>Each GAN is composed of a generator with UNet architecture and a discriminator (it could be normal one or a PatchGAN); samples from domain A are fed to the <span class="math notranslate nohighlight">\(GAN_{A \rightarrow B}\)</span>
whilst samples from domain B are fed to the <span class="math notranslate nohighlight">\(GAN_{B \rightarrow A}\)</span>. An adversarial loss is used as commonly done in GANs training, but in this case neither BCE nor Wasserstein is
chosen. Instead, the authors suggest to use an MSE loss:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathscr{L}_{adv, g_{A \rightarrow B}} &amp;= E_{\mathbf{x}_A \sim p_{x,A}} [(d_B(g_{A \rightarrow B}(\mathbf{x}_A) - 1)^2], \\
\mathscr{L}_{adv, g_{B \rightarrow A}} &amp;= E_{\mathbf{x}_B \sim p_{x,B}} [(d_A(g_{B \rightarrow A}(\mathbf{x}_B) - 1)^2], \\
\mathscr{L}_{adv, d_A} &amp;= E_{\mathbf{x}_A \sim p_{x,A}} [(d_A(\mathbf{x}_A) - 1)^2] + E_{\mathbf{x}_B \sim p_{x,B}} [d_B(g_{B \rightarrow A}(\mathbf{x}_B))^2], \\
\mathscr{L}_{adv, d_B} &amp;= E_{\mathbf{x}_B \sim p_{x,B}} [(d_B(\mathbf{x}_B) - 1)^2] + E_{\mathbf{x}_A \sim p_{x,A}} [d_B(g_{A \rightarrow B}(\mathbf{x}_A))^2], \\
\end{aligned}
\end{split}\]</div>
<p>and we finally define <span class="math notranslate nohighlight">\(\mathscr{L}_{adv, A \rightarrow B}=\mathscr{L}_{adv, g_{A \rightarrow B}} + \mathscr{L}_{adv, d_B}\)</span> and
<span class="math notranslate nohighlight">\(\mathscr{L}_{adv, B \rightarrow A}=\mathscr{L}_{adv, g_{B \rightarrow A}} + \mathscr{L}_{adv, d_A}\)</span>.</p>
<p>Moreover, since we do not know how to pair the samples from the different domains the PixelLoss of Pix2Pix
cannot be used here. Up until now the networks are also not aware of each other and could well be trained separately. A feedback loop is therefore introduced
such that the two networks are aware of each other and trained together to learn both mappings consistently. This is referred to as <em>Cycle consistency</em> and it works as follows:</p>
<ul class="simple">
<li><p>A sample from domain A is fed to the <span class="math notranslate nohighlight">\(GAN_{A \rightarrow B}\)</span> and subsequently to <span class="math notranslate nohighlight">\(GAN_{B \rightarrow A}\)</span> and the reconstruction loss is computed:
<span class="math notranslate nohighlight">\(\mathscr{L}_{cycle, A \rightarrow B} = MSE(\mathbf{x}_A, g_{B \rightarrow A}(g_{A \rightarrow B}(\mathbf{x}_A))\)</span></p></li>
<li><p>A sample from domain B is fed to the <span class="math notranslate nohighlight">\(GAN_{B \rightarrow A}\)</span> and subsequently to <span class="math notranslate nohighlight">\(GAN_{A \rightarrow B}\)</span> and the reconstruction loss is computed:
<span class="math notranslate nohighlight">\(\mathscr{L}_{cycle, B \rightarrow A} = MSE(\mathbf{x}_B, g_{A \rightarrow B}(g_{B \rightarrow A}(\mathbf{x}_B))\)</span></p></li>
</ul>
<p>Finally, an Identity loss is also optionally introduced where a sample from one domain is passed through the generator of the other domain and the MSE loss is computed against
the sample itself. The idea of such loss is that a generator should not modify a sample that already belongs to the target distribution:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathscr{L}_{identity, A} &amp;= MSE(g_{B \rightarrow A}(\mathbf{x}_A), \mathbf{x}_A)\\
\mathscr{L}_{identity, B} &amp;= MSE(g_{A \rightarrow B}(\mathbf{x}_B), \mathbf{x}_B)\\
\end{aligned}
\end{split}\]</div>
<p>To summarize, the overall loss function of CycleGAN becomes:</p>
<div class="math notranslate nohighlight">
\[
\mathscr{L} = \sum_{i \in (A \rightarrow B, B \rightarrow A)} \left( \mathscr{L}_{adv, i} + \lambda_C (\mathscr{L}_{cycle, i}) \right) + 
\lambda_I (\mathscr{L}_{identity, A} +\mathscr{L}_{identity, B})
\]</div>
</section>
</section>
<section id="additional-readings">
<h2>Additional readings<a class="headerlink" href="#additional-readings" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>A good discussion on the limitations of the BCE loss for GANs training can be found <a class="reference external" href="https://jonathan-hui.medium.com/gan-what-is-wrong-with-the-gan-cost-function-6f594162ce01">here</a></p></li>
<li><p>A number of valuable resources for stable training of GANs are: <a class="reference external" href="https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/">1</a>,
<a class="reference external" href="https://towardsdatascience.com/gan-ways-to-improve-gan-performance-acf37f9f59b">2</a></p></li>
<li><p>If you want to get started with GANs in PyTorch, here is a good starting point:
<a class="reference external" href="https://github.com/eriklindernoren/PyTorch-GAN">A Zoo of PyTorch implementations of GANs</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gans-groundbreaking-idea">GANs groundbreaking idea</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematics-of-gans">Mathematics of GANs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-of-gans">Training of GANs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mode-collapse">Mode collapse</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vanishing-gradients">Vanishing gradients</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions-to-unstable-training">Solutions to unstable training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-gans">Conditional GANs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#domain-translation-with-gans">Domain translation with GANs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#paired-training">Paired training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unpaired-training">Unpaired training</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-readings">Additional readings</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ashok Dahal, Modified from the Content of Matteo Ravasi, KAUST
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>